{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fine-Tuning Bert_Highest-reddit.ipynb","provenance":[{"file_id":"1FdZjlf-71sxhRiAzpixL6KhFr69JBLyW","timestamp":1621792346628},{"file_id":"1ftGKQ22ZBSIX_d6KEpUI7vRczYgtQPMF","timestamp":1620983839237},{"file_id":"https://github.com/prateekjoshi565/Fine-Tuning-BERT/blob/master/Fine_Tuning_BERT_for_Spam_Classification.ipynb","timestamp":1619947106006}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"946c8603cf7144d7b0891ef2a50cb01f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_785d647ef0214d269b9dcd030a2a5a36","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4f3de02eb26c48a29541a79b90c85a3a","IPY_MODEL_d551eba107bb48839cf51f54693837b6"]}},"785d647ef0214d269b9dcd030a2a5a36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f3de02eb26c48a29541a79b90c85a3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a421459ff5674c8a93984b0e9486faa4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9fdbe86a02be4bf78677344cf58adcfb"}},"d551eba107bb48839cf51f54693837b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9fe08fad1d024dae8170d50c4d19bc7c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:18&lt;00:00, 30.2B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6e2547da0d8c4695905d30175152032c"}},"a421459ff5674c8a93984b0e9486faa4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9fdbe86a02be4bf78677344cf58adcfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9fe08fad1d024dae8170d50c4d19bc7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6e2547da0d8c4695905d30175152032c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69b710d632d2474990d8919c1f7727e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0813446751b1414b8e43c677a4fd0206","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e3771ab7584445a1b4925d13e2c36fcc","IPY_MODEL_8098b5336fbf4789bb05cd76fcbe4e5a"]}},"0813446751b1414b8e43c677a4fd0206":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e3771ab7584445a1b4925d13e2c36fcc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4cd11bdc75124a1298b6554834806225","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1200755c524f4d6b98d24a04ced188ee"}},"8098b5336fbf4789bb05cd76fcbe4e5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4a510640b79b4792be083fa997e555e4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:13&lt;00:00, 31.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_24769c3b7a45439ca3436ac7c38738df"}},"4cd11bdc75124a1298b6554834806225":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1200755c524f4d6b98d24a04ced188ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a510640b79b4792be083fa997e555e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"24769c3b7a45439ca3436ac7c38738df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1597850c6ef445a08b7aa0fecc3fb07f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5023ea6d209d4911a1ab7657b2636c75","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4dd9166e7c614f489b309037dd30b6c4","IPY_MODEL_0f8ffac1c4c74b998d7d429e8c348a17"]}},"5023ea6d209d4911a1ab7657b2636c75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4dd9166e7c614f489b309037dd30b6c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_41bcfae81608463b97c95d12367cef1d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_12af88cd8d7d427694bf65061f87acff"}},"0f8ffac1c4c74b998d7d429e8c348a17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8dcc034acca245a898b7c6aaf5ea64c4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:01&lt;00:00, 195kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89cded0a14c14b93aa08af371d040db4"}},"41bcfae81608463b97c95d12367cef1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"12af88cd8d7d427694bf65061f87acff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8dcc034acca245a898b7c6aaf5ea64c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"89cded0a14c14b93aa08af371d040db4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3fff1ab1cb8c411d9a1c3662b364ce58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d15e2b2e623f49a98af0dab4b40191ab","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6dcd0c9a8b5948b58f90606a3d249b6a","IPY_MODEL_b3eefe0a3f0445f89f4f5b07715c7a29"]}},"d15e2b2e623f49a98af0dab4b40191ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6dcd0c9a8b5948b58f90606a3d249b6a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9b4ff25e6f1949f5a33ff97eabd2b493","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bda7db6757824ec8aa0b8725e0928aab"}},"b3eefe0a3f0445f89f4f5b07715c7a29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5973be6f3957470c9f285c5cc6eb4c58","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:01&lt;00:00, 284kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ada8ae79736842c5b41ee3f597d27116"}},"9b4ff25e6f1949f5a33ff97eabd2b493":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bda7db6757824ec8aa0b8725e0928aab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5973be6f3957470c9f285c5cc6eb4c58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ada8ae79736842c5b41ee3f597d27116":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b84ed14719b40e6a5377463ae84f085":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_811209e2c52a4240972266a6e666062c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ff14c6b7700243a6894187caeba5a7da","IPY_MODEL_062a94c034054bc7a4c3e3181423ce63"]}},"811209e2c52a4240972266a6e666062c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ff14c6b7700243a6894187caeba5a7da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5d204c1d0d204420be99764491b1387d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7c42294b1b2c4006a26f93acb0ee577f"}},"062a94c034054bc7a4c3e3181423ce63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_684bd68afc6944959793de8e8021d6d6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 172B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_061d379faa774807b58e466cc4cb8906"}},"5d204c1d0d204420be99764491b1387d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7c42294b1b2c4006a26f93acb0ee577f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"684bd68afc6944959793de8e8021d6d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"061d379faa774807b58e466cc4cb8906":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"OFOTiqrtNvyy"},"source":["# Install Transformers Library"]},{"cell_type":"code","metadata":{"id":"1hkhc10wNrGt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621936809089,"user_tz":-330,"elapsed":9060,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"a659d7c5-75d3-4495-e489-36d880dbf6b1"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 9.4MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 26.8MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 34.5MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4giRzM7NtHJ"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast\n","from transformers import RobertaTokenizer, RobertaModel\n","# specify GPU\n","device = torch.device(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7sYuExU3YiR4","executionInfo":{"status":"ok","timestamp":1621936851155,"user_tz":-330,"elapsed":35325,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"64c37e11-3469-453d-fe2a-dee954ba2b30"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kKd-Tj3hOMsZ"},"source":["# Load Dataset"]},{"cell_type":"code","metadata":{"id":"cwJrQFQgN_BE","colab":{"base_uri":"https://localhost:8080/","height":230},"executionInfo":{"status":"ok","timestamp":1621936910869,"user_tz":-330,"elapsed":4502,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"fa780f04-2077-44c7-fe19-70f5040fe546"},"source":["df = pd.read_json('/content/drive/MyDrive/sarcasm detection/Datasets/reddit/sarcasm_detection_shared_task_reddit_training.jsonl',lines=True)\n","df1 = pd.read_json('/content/drive/MyDrive/sarcasm detection/Datasets/reddit/sarcasm_detection_shared_task_reddit_testing.jsonl',lines=True)\n","\n","df['labels'] = df['label'].apply(lambda x: ['SARCASM', 'NOT_SARCASM'].index(x))\n","df1['labels'] = df1['label'].apply(lambda x: ['SARCASM', 'NOT_SARCASM'].index(x))\n","df1.tail()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>context</th>\n","      <th>response</th>\n","      <th>id</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1795</th>\n","      <td>SARCASM</td>\n","      <td>[Spoiler Cristiane Justino vs. Amanda Nunes, H...</td>\n","      <td>she will probably beat him too. she can fight ...</td>\n","      <td>reddit_1796</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1796</th>\n","      <td>NOT_SARCASM</td>\n","      <td>[Treyarch makes the most unbalanced game ever....</td>\n","      <td>No, but then the game really glitch(ed) out fo...</td>\n","      <td>reddit_1797</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1797</th>\n","      <td>SARCASM</td>\n","      <td>[First Official Image from \"Zombieland: Double...</td>\n","      <td>&gt; Zombieland ~~2:~~ Double Tap They changed it...</td>\n","      <td>reddit_1798</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1798</th>\n","      <td>SARCASM</td>\n","      <td>[Its time to ban /r/The_Donald: Calling out sp...</td>\n","      <td>We're not *supporting racists* and prospective...</td>\n","      <td>reddit_1799</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1799</th>\n","      <td>SARCASM</td>\n","      <td>[59 Alabama ministers sign a letter saying Roy...</td>\n","      <td>Is she old enough to have Facebook</td>\n","      <td>reddit_1800</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            label  ... labels\n","1795      SARCASM  ...      0\n","1796  NOT_SARCASM  ...      1\n","1797      SARCASM  ...      0\n","1798      SARCASM  ...      0\n","1799      SARCASM  ...      0\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"U7WBye79ZKoO"},"source":["df[\"tweets\"]=df['response']\n","df1[\"tweets\"]=df1['response']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fzPPOrVQWiW5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621936910871,"user_tz":-330,"elapsed":23,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"60f56001-6cbf-49d9-ad8b-68bcdafcd057"},"source":["df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4400, 5)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"676DPU1BOPdp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621936910871,"user_tz":-330,"elapsed":16,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"913e40b7-3beb-49b3-b5a3-24fa66c5675a"},"source":["# check class distribution\n","df['labels'].value_counts(normalize = True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    0.5\n","0    0.5\n","Name: labels, dtype: float64"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"MKfWnApvOoE7"},"source":["# Split train dataset into train, validation and test sets"]},{"cell_type":"code","metadata":{"id":"mfhSPF5jOWb7"},"source":["\n","X_s = df['tweets'].values\n","y_s = df['labels'].values\n","\n","Xt_s = df1['tweets'].values\n","yt_s = df1['labels'].values\n","\n","train_text, temp_text, train_labels, temp_labels = X_s,Xt_s,y_s,yt_s\n","\n","# we will use temp_text and temp_labels to create validation and test set\n","val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n","                                                                random_state=2018, \n","                                                                test_size=0.5, \n","                                                                stratify=temp_labels)\n","val_text, test_text, val_labels, test_labels=temp_text, temp_text, temp_labels, temp_labels\n","\n","# X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.2, random_state=42)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1jEFb39cCjk","executionInfo":{"status":"ok","timestamp":1621936917590,"user_tz":-330,"elapsed":6015,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"7cdb57b0-050d-405b-9a4e-fe65cd64564b"},"source":["# pip install -U sentence-transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting sentence-transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/75/df441011cd1726822b70fbff50042adb4860e9327b99b346154ead704c44/sentence-transformers-1.2.0.tar.gz (81kB)\n","\r\u001b[K     |████                            | 10kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 19.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 30kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 40kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 51kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 61kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 71kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.6.1)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n","Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n","Requirement already satisfied, skipping upgrade: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.9.1+cu101)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n","Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n","Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 25.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n","Requirement already satisfied, skipping upgrade: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.8)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n","Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.3)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n","Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.45)\n","Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (4.0.1)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (8.0.0)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-1.2.0-cp37-none-any.whl size=123339 sha256=faaaf070983c1a4175aafd3fa0c237696c085a28d085778973a29dd9da5fc9aa\n","  Stored in directory: /root/.cache/pip/wheels/0f/06/f7/faaa96fdda87462b4fd5c47b343340e9d5531ef70d0eef8242\n","Successfully built sentence-transformers\n","Installing collected packages: sentencepiece, sentence-transformers\n","Successfully installed sentence-transformers-1.2.0 sentencepiece-0.1.95\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n7hsdLoCO7uB"},"source":["# Import BERT Model and BERT Tokenizer"]},{"cell_type":"code","metadata":{"id":"S1kY3gZjO2RE","colab":{"base_uri":"https://localhost:8080/","height":330,"referenced_widgets":["946c8603cf7144d7b0891ef2a50cb01f","785d647ef0214d269b9dcd030a2a5a36","4f3de02eb26c48a29541a79b90c85a3a","d551eba107bb48839cf51f54693837b6","a421459ff5674c8a93984b0e9486faa4","9fdbe86a02be4bf78677344cf58adcfb","9fe08fad1d024dae8170d50c4d19bc7c","6e2547da0d8c4695905d30175152032c","69b710d632d2474990d8919c1f7727e9","0813446751b1414b8e43c677a4fd0206","e3771ab7584445a1b4925d13e2c36fcc","8098b5336fbf4789bb05cd76fcbe4e5a","4cd11bdc75124a1298b6554834806225","1200755c524f4d6b98d24a04ced188ee","4a510640b79b4792be083fa997e555e4","24769c3b7a45439ca3436ac7c38738df","1597850c6ef445a08b7aa0fecc3fb07f","5023ea6d209d4911a1ab7657b2636c75","4dd9166e7c614f489b309037dd30b6c4","0f8ffac1c4c74b998d7d429e8c348a17","41bcfae81608463b97c95d12367cef1d","12af88cd8d7d427694bf65061f87acff","8dcc034acca245a898b7c6aaf5ea64c4","89cded0a14c14b93aa08af371d040db4","3fff1ab1cb8c411d9a1c3662b364ce58","d15e2b2e623f49a98af0dab4b40191ab","6dcd0c9a8b5948b58f90606a3d249b6a","b3eefe0a3f0445f89f4f5b07715c7a29","9b4ff25e6f1949f5a33ff97eabd2b493","bda7db6757824ec8aa0b8725e0928aab","5973be6f3957470c9f285c5cc6eb4c58","ada8ae79736842c5b41ee3f597d27116","7b84ed14719b40e6a5377463ae84f085","811209e2c52a4240972266a6e666062c","ff14c6b7700243a6894187caeba5a7da","062a94c034054bc7a4c3e3181423ce63","5d204c1d0d204420be99764491b1387d","7c42294b1b2c4006a26f93acb0ee577f","684bd68afc6944959793de8e8021d6d6","061d379faa774807b58e466cc4cb8906"]},"executionInfo":{"status":"ok","timestamp":1621936937199,"user_tz":-330,"elapsed":19615,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"a2a86874-bf4b-4828-c7e5-ca2ecc51fa17"},"source":["# import BERT-base pretrained model\n","bert = AutoModel.from_pretrained('bert-base-uncased')\n","\n","# Load the BERT tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"946c8603cf7144d7b0891ef2a50cb01f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69b710d632d2474990d8919c1f7727e9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1597850c6ef445a08b7aa0fecc3fb07f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3fff1ab1cb8c411d9a1c3662b364ce58","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b84ed14719b40e6a5377463ae84f085","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_zOKeOMeO-DT"},"source":["# sample data\n","text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n","# encode text\n","sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oAH73n39PHLw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621936948622,"user_tz":-330,"elapsed":3,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"d879fcaa-c1db-4c97-950a-c15465d03699"},"source":["# output\n","print(sent_id)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8wIYaWI_Prg8"},"source":["# Tokenization"]},{"cell_type":"code","metadata":{"id":"yKwbpeN_PMiu","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"ok","timestamp":1621936952293,"user_tz":-330,"elapsed":1199,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"0e9ecda4-1d6a-477b-b6fe-fcce1fe16284"},"source":["# get length of all the messages in the train set\n","seq_len = [len(i.split()) for i in train_text]\n","\n","pd.Series(seq_len).hist(bins = 30)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f01ddeb2590>"]},"metadata":{"tags":[]},"execution_count":16},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXCUlEQVR4nO3df5BV9X3G8fcTVMy4DmC0OxSYQho6GSINkS2YSSazq6MidoqZsRkcRsGYIW2xTSamFZNJNSozpDWxdWJMN4WIMcmGmjgyiLUE2XH8A1ES5IfGsFHSuENkIojZmNJqPv3jflev27vs2T27ew/9Pq+ZO3vP93zPvc89sPtwzj17UURgZmZ5ekezA5iZWfO4BMzMMuYSMDPLmEvAzCxjLgEzs4yd0uwAJ3L22WfHzJkzC839zW9+wxlnnDG2gUpwvnKcrxznG7kqZ4PG+Xbt2vWriDin0ANERGVv8+fPj6K2b99eeG4zOF85zleO841clbNFNM4HPBUFf876dJCZWcZcAmZmGXMJmJllzCVgZpYxl4CZWcZcAmZmGXMJmJllzCVgZpYxl4CZWcYq/bERZc1c/VCheQfXXjbGSczMqmnIIwFJp0vaKelpSfslfTGN3yPpBUm7021eGpekOyX1SNoj6by6x1ou6UC6LR+7l2VmZkUUORI4DlwQEX2STgUel/RwWve3EXH/gPmXArPTbSFwN7BQ0lnATUAbEMAuSZsi4uhovBAzMxu+IY8E0ucR9aXFU9PtRP8x8RLg3rTdDmCypKnAJcDWiDiSfvBvBRaVi29mZmUUemNY0gRJu4HD1H6QP5FWrUmnfO6QNDGNTQN+Ubf5i2lssHEzM2sS1T51tOBkaTLwAPDXwMvAL4HTgE7gZxFxi6TNwNqIeDxtsw24AWgHTo+I29L4F4DfRsTtA55jJbASoLW1dX5XV1ehbH19fbS0tLxtbG/vsULbzp02qdC8MhrlqxLnK8f5yqlyvipng8b5Ojo6dkVEW5Hth3V1UES8Imk7sKjuh/dxSd8EPpuWe4EZdZtNT2O91Iqgfry7wXN0UisV2traor29feCUhrq7uxk4d0XRq4OWFXuOMhrlqxLnK8f5yqlyvipng/L5ilwddE46AkDSO4GLgJ+k8/xIEnA5sC9tsgm4Ol0ldD5wLCIOAY8AF0uaImkKcHEaMzOzJilyJDAV2CBpArXS2BgRmyU9KukcQMBu4C/S/C3AYqAHeA24BiAijki6FXgyzbslIo6M3ksxM7PhGrIEImIP8IEG4xcMMj+AVYOsWw+sH2ZGMzMbI/7YCDOzjLkEzMwy5hIwM8uYS8DMLGMuATOzjLkEzMwy5hIwM8uYS8DMLGMuATOzjLkEzMwy5hIwM8uYS8DMLGMuATOzjLkEzMwy5hIwM8uYS8DMLGMuATOzjLkEzMwy5hIwM8uYS8DMLGNDloCk0yXtlPS0pP2SvpjGZ0l6QlKPpO9JOi2NT0zLPWn9zLrHujGNPyfpkrF6UWZmVkyRI4HjwAUR8X5gHrBI0vnAl4A7IuI9wFHg2jT/WuBoGr8jzUPSHGAp8D5gEfA1SRNG88WYmdnwDFkCUdOXFk9NtwAuAO5P4xuAy9P9JWmZtP5CSUrjXRFxPCJeAHqABaPyKszMbEQUEUNPqv2LfRfwHuAu4B+BHelf+0iaATwcEedK2gcsiogX07qfAQuBm9M296XxdWmb+wc810pgJUBra+v8rq6uQi+kr6+PlpaWt43t7T1WaNu50yYVmldGo3xV4nzlOF85Vc5X5WzQOF9HR8euiGgrsv0pRSZFxBvAPEmTgQeA9w43aFER0Ql0ArS1tUV7e3uh7bq7uxk4d8Xqhwpte3BZsecoo1G+KnG+cpyvnCrnq3I2KJ9vWFcHRcQrwHbgg8BkSf0lMh3oTfd7gRkAaf0k4OX68QbbmJlZExS5OuicdASApHcCFwHPUiuDK9K05cCD6f6mtExa/2jUzjltApamq4dmAbOBnaP1QszMbPiKnA6aCmxI7wu8A9gYEZslPQN0SboN+DGwLs1fB3xLUg9whNoVQUTEfkkbgWeA14FV6TSTmZk1yZAlEBF7gA80GH+eBlf3RMR/AX8+yGOtAdYMP6aZmY0F/8awmVnGXAJmZhlzCZiZZcwlYGaWMZeAmVnGXAJmZhlzCZiZZcwlYGaWMZeAmVnGXAJmZhlzCZiZZcwlYGaWMZeAmVnGXAJmZhlzCZiZZcwlYGaWMZeAmVnGXAJmZhlzCZiZZcwlYGaWsSFLQNIMSdslPSNpv6RPpfGbJfVK2p1ui+u2uVFSj6TnJF1SN74ojfVIWj02L8nMzIo6pcCc14HrI+JHks4EdknamtbdERG310+WNAdYCrwP+H3gh5L+KK2+C7gIeBF4UtKmiHhmNF6ImZkN35AlEBGHgEPp/q8lPQtMO8EmS4CuiDgOvCCpB1iQ1vVExPMAkrrSXJeAmVmTKCKKT5ZmAo8B5wKfAVYArwJPUTtaOCrpq8COiLgvbbMOeDg9xKKI+EQavwpYGBHXDXiOlcBKgNbW1vldXV2FsvX19dHS0vK2sb29xwptO3fapELzymiUr0qcrxznK6fK+aqcDRrn6+jo2BURbUW2L3I6CABJLcD3gU9HxKuS7gZuBSJ9/TLw8aKPN5iI6AQ6Adra2qK9vb3Qdt3d3Qycu2L1Q4W2Pbis2HOU0ShflThfOc5XTpXzVTkblM9XqAQknUqtAL4dET8AiIiX6tZ/A9icFnuBGXWbT09jnGDczMyaoMjVQQLWAc9GxFfqxqfWTfsosC/d3wQslTRR0ixgNrATeBKYLWmWpNOovXm8aXRehpmZjUSRI4EPAVcBeyXtTmOfA66UNI/a6aCDwCcBImK/pI3U3vB9HVgVEW8ASLoOeASYAKyPiP2j+FrMzGyYilwd9DigBqu2nGCbNcCaBuNbTrSdmZmNL//GsJlZxlwCZmYZcwmYmWXMJWBmljGXgJlZxlwCZmYZcwmYmWXMJWBmljGXgJlZxlwCZmYZcwmYmWXMJWBmljGXgJlZxlwCZmYZcwmYmWXMJWBmljGXgJlZxlwCZmYZcwmYmWXMJWBmlrEhS0DSDEnbJT0jab+kT6XxsyRtlXQgfZ2SxiXpTkk9kvZIOq/usZan+QckLR+7l2VmZkUUORJ4Hbg+IuYA5wOrJM0BVgPbImI2sC0tA1wKzE63lcDdUCsN4CZgIbAAuKm/OMzMrDmGLIGIOBQRP0r3fw08C0wDlgAb0rQNwOXp/hLg3qjZAUyWNBW4BNgaEUci4iiwFVg0qq/GzMyGRRFRfLI0E3gMOBf4z4iYnMYFHI2IyZI2A2sj4vG0bhtwA9AOnB4Rt6XxLwC/jYjbBzzHSmpHELS2ts7v6uoqlK2vr4+Wlpa3je3tPVZo27nTJhWaV0ajfFXifOU4XzlVzlflbNA4X0dHx66IaCuy/SlFn0hSC/B94NMR8Wrt535NRISk4m1yAhHRCXQCtLW1RXt7e6Hturu7GTh3xeqHCm17cFmx5yijUb4qcb5ynK+cKuercjYon6/Q1UGSTqVWAN+OiB+k4ZfSaR7S18NpvBeYUbf59DQ22LiZmTVJkauDBKwDno2Ir9St2gT0X+GzHHiwbvzqdJXQ+cCxiDgEPAJcLGlKekP44jRmZmZNUuR00IeAq4C9knansc8Ba4GNkq4Ffg58LK3bAiwGeoDXgGsAIuKIpFuBJ9O8WyLiyKi8CjMzG5EhSyC9watBVl/YYH4AqwZ5rPXA+uEENDOzsePfGDYzy5hLwMwsYy4BM7OMuQTMzDLmEjAzy5hLwMwsYy4BM7OMuQTMzDLmEjAzy5hLwMwsYy4BM7OMuQTMzDLmEjAzy5hLwMwsYy4BM7OMuQTMzDLmEjAzy5hLwMwsYy4BM7OMuQTMzDI2ZAlIWi/psKR9dWM3S+qVtDvdFtetu1FSj6TnJF1SN74ojfVIWj36L8XMzIaryJHAPcCiBuN3RMS8dNsCIGkOsBR4X9rma5ImSJoA3AVcCswBrkxzzcysiU4ZakJEPCZpZsHHWwJ0RcRx4AVJPcCCtK4nIp4HkNSV5j4z7MRmZjZqFBFDT6qVwOaIODct3wysAF4FngKuj4ijkr4K7IiI+9K8dcDD6WEWRcQn0vhVwMKIuK7Bc60EVgK0trbO7+rqKvRC+vr6aGlpedvY3t5jhbadO21SoXllNMpXJc5XjvOVU+V8Vc4GjfN1dHTsioi2ItsPeSQwiLuBW4FIX78MfHyEj/U2EdEJdAK0tbVFe3t7oe26u7sZOHfF6ocKbXtwWbHnKKNRvipxvnKcr5wq56tyNiifb0QlEBEv9d+X9A1gc1rsBWbUTZ2exjjBuJmZNcmILhGVNLVu8aNA/5VDm4ClkiZKmgXMBnYCTwKzJc2SdBq1N483jTy2mZmNhiGPBCR9F2gHzpb0InAT0C5pHrXTQQeBTwJExH5JG6m94fs6sCoi3kiPcx3wCDABWB8R+0f91ZiZ2bAUuTroygbD604wfw2wpsH4FmDLsNKZmdmY8m8Mm5llzCVgZpYxl4CZWcZcAmZmGXMJmJllzCVgZpYxl4CZWcZcAmZmGXMJmJllzCVgZpYxl4CZWcZcAmZmGXMJmJllzCVgZpYxl4CZWcZcAmZmGXMJmJllzCVgZpYxl4CZWcZcAmZmGRuyBCStl3RY0r66sbMkbZV0IH2dksYl6U5JPZL2SDqvbpvlaf4BScvH5uWYmdlwFDkSuAdYNGBsNbAtImYD29IywKXA7HRbCdwNtdIAbgIWAguAm/qLw8zMmmfIEoiIx4AjA4aXABvS/Q3A5XXj90bNDmCypKnAJcDWiDgSEUeBrfzfYjEzs3GmiBh6kjQT2BwR56blVyJicrov4GhETJa0GVgbEY+ndduAG4B24PSIuC2NfwH4bUTc3uC5VlI7iqC1tXV+V1dXoRfS19dHS0vL28b29h4rtO3caZMKzSujUb4qcb5ynK+cKuercjZonK+jo2NXRLQV2f6UsgEiIiQN3STFH68T6ARoa2uL9vb2Qtt1d3czcO6K1Q8V2vbgsmLPUUajfFXifOU4XzlVzlflbFA+30ivDnopneYhfT2cxnuBGXXzpqexwcbNzKyJRloCm4D+K3yWAw/WjV+drhI6HzgWEYeAR4CLJU1JbwhfnMbMzKyJhjwdJOm71M7pny3pRWpX+awFNkq6Fvg58LE0fQuwGOgBXgOuAYiII5JuBZ5M826JiIFvNpuZ2TgbsgQi4spBVl3YYG4AqwZ5nPXA+mGlMzOzMeXfGDYzy5hLwMwsYy4BM7OMuQTMzDLmEjAzy5hLwMwsYy4BM7OMuQTMzDLmEjAzy5hLwMwsYy4BM7OMlf7/BP4/mFn0/x1Ye9kYJzEzG18+EjAzy5hLwMwsYy4BM7OMuQTMzDLmEjAzy5hLwMwsYy4BM7OMuQTMzDJWqgQkHZS0V9JuSU+lsbMkbZV0IH2dksYl6U5JPZL2SDpvNF6AmZmN3GgcCXRExLyIaEvLq4FtETEb2JaWAS4FZqfbSuDuUXhuMzMrYSxOBy0BNqT7G4DL68bvjZodwGRJU8fg+c3MrCBFxMg3ll4AjgIB/EtEdEp6JSImp/UCjkbEZEmbgbUR8Xhatw24ISKeGvCYK6kdKdDa2jq/q6urUJa+vj5aWlreNra399iIX1sjc6dNGvG2jfJVifOV43zlVDlflbNB43wdHR276s7OnFDZD5D7cET0Svo9YKukn9SvjIiQNKyWiYhOoBOgra0t2tvbC23X3d3NwLkrCn4wXFEHlxXL0kijfFXifOU4XzlVzlflbFA+X6nTQRHRm74eBh4AFgAv9Z/mSV8Pp+m9wIy6zaenMTMza5IRl4CkMySd2X8fuBjYB2wClqdpy4EH0/1NwNXpKqHzgWMRcWjEyc3MrLQyp4NagQdqp/05BfhORPy7pCeBjZKuBX4OfCzN3wIsBnqA14BrSjy3mZmNghGXQEQ8D7y/wfjLwIUNxgNYNdLnMzOz0effGDYzy5hLwMwsYy4BM7OMuQTMzDLmEjAzy5hLwMwsYy4BM7OMuQTMzDLmEjAzy5hLwMwsYy4BM7OMuQTMzDLmEjAzy5hLwMwsYy4BM7OMuQTMzDLmEjAzy5hLwMwsY2X+j+HszFz9UKF5B9deNsZJzMxGh48EzMwyNu4lIGmRpOck9UhaPd7Pb2ZmbxnXEpA0AbgLuBSYA1wpac54ZjAzs7eM93sCC4CeiHgeQFIXsAR4ZpxzjKlG7x1cP/d1VhR8T2Egv8dgZmNlvEtgGvCLuuUXgYX1EyStBFamxT5JzxV87LOBX5VOOEb+pkQ+fWmUwzRW6f2H85XlfCNX5WzQON8fFN24clcHRUQn0Dnc7SQ9FRFtYxBpVDhfOc5XjvONXJWzQfl84/3GcC8wo255ehozM7MmGO8SeBKYLWmWpNOApcCmcc5gZmbJuJ4OiojXJV0HPAJMANZHxP5Revhhn0IaZ85XjvOV43wjV+VsUDKfImK0gpiZ2UnGvzFsZpYxl4CZWcZO+hKo4sdQSDooaa+k3ZKeSmNnSdoq6UD6OmUc86yXdFjSvrqxhnlUc2fan3skndekfDdL6k37cLekxXXrbkz5npN0yTjkmyFpu6RnJO2X9Kk0Xol9eIJ8ldiHkk6XtFPS0ynfF9P4LElPpBzfSxeLIGliWu5J62c2Kd89kl6o23/z0ngzvkcmSPqxpM1pefT2XUSctDdqby7/DHg3cBrwNDCnArkOAmcPGPsHYHW6vxr40jjm+QhwHrBvqDzAYuBhQMD5wBNNyncz8NkGc+ekP+eJwKz05z9hjPNNBc5L988EfppyVGIfniBfJfZh2g8t6f6pwBNpv2wElqbxrwN/me7/FfD1dH8p8L0x3n+D5bsHuKLB/GZ8j3wG+A6wOS2P2r472Y8E3vwYioj4b6D/YyiqaAmwId3fAFw+Xk8cEY8BRwrmWQLcGzU7gMmSpjYh32CWAF0RcTwiXgB6qP09GDMRcSgifpTu/xp4ltpvv1diH54g32DGdR+m/dCXFk9NtwAuAO5P4wP3X/9+vR+4UJKakG8w4/rnK2k6cBnwr2lZjOK+O9lLoNHHUJzoL/94CeA/JO1S7WMwAFoj4lC6/0ugtTnR3jRYnirt0+vS4fb6utNnTc2XDq8/QO1fi5XbhwPyQUX2YTqdsRs4DGyldvTxSkS83iDDm/nS+mPAu8YzX0T07781af/dIWniwHwNso+FfwL+DvhdWn4Xo7jvTvYSqKoPR8R51D4tdZWkj9SvjNqxWmWuza1anuRu4A+BecAh4MvNjQOSWoDvA5+OiFfr11VhHzbIV5l9GBFvRMQ8ap8SsAB4b7OyNDIwn6RzgRup5fwT4CzghvHOJelPgcMRsWusnuNkL4FKfgxFRPSmr4eBB6j9pX+p/5AxfT3cvIRwgjyV2KcR8VL6xvwd8A3eOl3RlHySTqX2A/bbEfGDNFyZfdgoX9X2Ycr0CrAd+CC10yj9v7Ban+HNfGn9JODlcc63KJ1mi4g4DnyT5uy/DwF/JukgtdPdFwD/zCjuu5O9BCr3MRSSzpB0Zv994GJgX8q1PE1bDjzYnIRvGizPJuDqdAXE+cCxulMe42bAOdaPUtuH/fmWpqsgZgGzgZ1jnEXAOuDZiPhK3apK7MPB8lVlH0o6R9LkdP+dwEXU3rfYDlyRpg3cf/379Qrg0XSkNZ75flJX8KJ2zr1+/43Ln29E3BgR0yNiJrWfb49GxDJGc9+N9bvaY32j9k79T6mdY/x8BfK8m9qVF08D+/szUTsvtw04APwQOGscM32X2umA/6F2/vDawfJQu+LhrrQ/9wJtTcr3rfT8e9Jf7Kl18z+f8j0HXDoO+T5M7VTPHmB3ui2uyj48Qb5K7EPgj4Efpxz7gL+v+17ZSe2N6X8DJqbx09NyT1r/7iblezTtv33Afbx1BdG4f4+k523nrauDRm3f+WMjzMwydrKfDjIzsxJcAmZmGXMJmJllzCVgZpYxl4CZWcZcAmZmGXMJmJll7H8BIEv530vw0sMAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"OXcswEIRPvGe"},"source":["max_seq_len = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tk5S7DWaP2t6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621936955002,"user_tz":-330,"elapsed":5,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"d14b5778-4797-4af6-db38-33a0a0dd434e"},"source":["# tokenize and encode sequences in the training set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Wsm8bkRZQTw9"},"source":["# Convert Integer Sequences to Tensors"]},{"cell_type":"code","metadata":{"id":"QR-lXwmzQPd6"},"source":["# for train set\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","# for validation set\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","# for test set\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ov1cOBlcRLuk"},"source":["# Create DataLoaders"]},{"cell_type":"code","metadata":{"id":"qUy9JKFYQYLp"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","#define a batch size\n","batch_size = 32\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K2HZc5ZYRV28"},"source":["# Freeze BERT Parameters"]},{"cell_type":"code","metadata":{"id":"wHZ0MC00RQA_"},"source":["# freeze all the parameters\n","for param in bert.parameters():\n","    param.requires_grad = True\n","# print(bert)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s7ahGBUWRi3X"},"source":["# Define Model Architecture"]},{"cell_type":"code","metadata":{"id":"b3iEtGyYRd0A"},"source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, bert):\n","      \n","      super(BERT_Arch, self).__init__()\n","\n","      self.bert = bert \n","      \n","      # dropout layer\n","      self.dropout = nn.Dropout(0.1)\n","      \n","      # relu activation function\n","      self.relu =  nn.ReLU()\n","\n","      # dense layer 1\n","      self.fc1 = nn.Linear(768,512)\n","      \n","      # dense layer 2 (Output layer)\n","      self.fc2 = nn.Linear(512,2)\n","\n","      #softmax activation function\n","      self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","\n","      #pass the inputs to the model  \n","      _, cls_hs = self.bert(sent_id,mask, return_dict=False)\n","      \n","      x = self.fc1(cls_hs)\n","\n","      x = self.relu(x)\n","\n","      x = self.dropout(x)\n","\n","      # output layer\n","      x = self.fc2(x)\n","      \n","      # apply softmax activation\n","      x = self.softmax(x)\n","\n","      return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cBAJJVuJRliv"},"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(bert)\n","\n","# push the model to GPU\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"taXS0IilRn9J"},"source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = AdamW(model.parameters(), lr = 2e-5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j9CDpoMQR_rK"},"source":["# Find Class Weights"]},{"cell_type":"code","metadata":{"id":"izY5xH5eR7Ur","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621936974798,"user_tz":-330,"elapsed":7,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"305c6ed0-2086-4967-8492-5255a7962dff"},"source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","#compute the class weights\n","class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n","\n","print(class_wts)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1. 1.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r1WvfY2vSGKi"},"source":["# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","cross_entropy  = nn.NLLLoss(weight=weights) \n","\n","# number of training epochs\n","epochs = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"My4CA0qaShLq"},"source":["# Fine-Tune BERT"]},{"cell_type":"code","metadata":{"id":"rskLk8R_SahS"},"source":["# function to train the model\n","def train():\n","  \n","  model.train()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save model predictions\n","  total_preds=[]\n","  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):\n","    \n","    # progress update after every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n"," \n","    sent_id, mask, labels = batch\n","\n","    # clear previously calculated gradients \n","    model.zero_grad()        \n","\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask)\n","\n","    # compute the loss between actual and predicted values\n","    loss = cross_entropy(preds, labels)\n","\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    # update parameters\n","    optimizer.step()\n","\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)\n","  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yGXovFDlSxB5"},"source":["# function for evaluating the model\n","def evaluate():\n","  \n","  print(\"\\nEvaluating...\")\n","  \n","  # deactivate dropout layers\n","  model.eval()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save the model predictions\n","  total_preds = []\n","\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):\n","    \n","    # Progress update every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      \n","      # Calculate elapsed time in minutes.\n","      # elapsed = format_time(time.time() - t0)\n","            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","\n","    sent_id, mask, labels = batch\n","\n","    # deactivate autograd\n","    with torch.no_grad():\n","      \n","      # model predictions\n","      preds = model(sent_id, mask)\n","\n","      # compute the validation loss between actual and predicted values\n","      loss = cross_entropy(preds,labels)\n","\n","      total_loss = total_loss + loss.item()\n","\n","      preds = preds.detach().cpu().numpy()\n","\n","      total_preds.append(preds)\n","\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9KZEgxRRTLXG"},"source":["# Start Model Training"]},{"cell_type":"code","metadata":{"id":"k1USGTntS3TS","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1621938349221,"user_tz":-330,"elapsed":1365536,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"92cda53c-25dc-4344-e41d-f0bd0fa1c507"},"source":["# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","#for each epoch\n","epochs=10\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss,_ = train()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'saved_weights.pt')\n","\n","\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","\n","\n","    path = 'saved_weights.pt'\n","    model.load_state_dict(torch.load(path))\n","    with torch.no_grad():\n","      preds = model(test_seq.to(device), test_mask.to(device))\n","      preds = preds.detach().cpu().numpy()\n","      # model's performance\n","    preds = np.argmax(preds, axis = 1)\n","    print(classification_report(test_y, preds))\n","    \n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," Epoch 1 / 10\n","  Batch    50  of    138.\n","  Batch   100  of    138.\n","\n","Evaluating...\n","  Batch    50  of     57.\n","              precision    recall  f1-score   support\n","\n","           0       0.61      0.79      0.69       900\n","           1       0.70      0.51      0.59       900\n","\n","    accuracy                           0.65      1800\n","   macro avg       0.66      0.65      0.64      1800\n","weighted avg       0.66      0.65      0.64      1800\n","\n","\n","Training Loss: 0.636\n","Validation Loss: 0.651\n","\n"," Epoch 2 / 10\n","  Batch    50  of    138.\n","  Batch   100  of    138.\n","\n","Evaluating...\n","  Batch    50  of     57.\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.57      0.64       900\n","           1       0.64      0.78      0.71       900\n","\n","    accuracy                           0.68      1800\n","   macro avg       0.68      0.68      0.67      1800\n","weighted avg       0.68      0.68      0.67      1800\n","\n","\n","Training Loss: 0.521\n","Validation Loss: 0.633\n","\n"," Epoch 3 / 10\n","  Batch    50  of    138.\n","  Batch   100  of    138.\n","\n","Evaluating...\n","  Batch    50  of     57.\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.57      0.64       900\n","           1       0.64      0.78      0.71       900\n","\n","    accuracy                           0.68      1800\n","   macro avg       0.68      0.68      0.67      1800\n","weighted avg       0.68      0.68      0.67      1800\n","\n","\n","Training Loss: 0.370\n","Validation Loss: 0.808\n","\n"," Epoch 4 / 10\n","  Batch    50  of    138.\n","  Batch   100  of    138.\n","\n","Evaluating...\n","  Batch    50  of     57.\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.57      0.64       900\n","           1       0.64      0.78      0.71       900\n","\n","    accuracy                           0.68      1800\n","   macro avg       0.68      0.68      0.67      1800\n","weighted avg       0.68      0.68      0.67      1800\n","\n","\n","Training Loss: 0.372\n","Validation Loss: 0.737\n","\n"," Epoch 5 / 10\n","  Batch    50  of    138.\n","  Batch   100  of    138.\n","\n","Evaluating...\n","  Batch    50  of     57.\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.57      0.64       900\n","           1       0.64      0.78      0.71       900\n","\n","    accuracy                           0.68      1800\n","   macro avg       0.68      0.68      0.67      1800\n","weighted avg       0.68      0.68      0.67      1800\n","\n","\n","Training Loss: 0.382\n","Validation Loss: 0.741\n","\n"," Epoch 6 / 10\n","  Batch    50  of    138.\n","  Batch   100  of    138.\n","\n","Evaluating...\n","  Batch    50  of     57.\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.57      0.64       900\n","           1       0.64      0.78      0.71       900\n","\n","    accuracy                           0.68      1800\n","   macro avg       0.68      0.68      0.67      1800\n","weighted avg       0.68      0.68      0.67      1800\n","\n","\n","Training Loss: 0.383\n","Validation Loss: 0.710\n","\n"," Epoch 7 / 10\n","  Batch    50  of    138.\n","  Batch   100  of    138.\n","\n","Evaluating...\n","  Batch    50  of     57.\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.57      0.64       900\n","           1       0.64      0.78      0.71       900\n","\n","    accuracy                           0.68      1800\n","   macro avg       0.68      0.68      0.67      1800\n","weighted avg       0.68      0.68      0.67      1800\n","\n","\n","Training Loss: 0.383\n","Validation Loss: 0.732\n","\n"," Epoch 8 / 10\n","  Batch    50  of    138.\n","  Batch   100  of    138.\n","\n","Evaluating...\n","  Batch    50  of     57.\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-77926b674f3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m       \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m       \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0;31m# model's performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-3c83a23f0fef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m         )\n\u001b[1;32m    983\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m                 )\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m         )\n\u001b[1;32m    499\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m   1457\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.06 GiB (GPU 0; 11.17 GiB total capacity; 8.94 GiB already allocated; 194.81 MiB free; 10.55 GiB reserved in total by PyTorch)"]}]},{"cell_type":"markdown","metadata":{"id":"_yrhUc9kTI5a"},"source":["# Load Saved Model"]},{"cell_type":"code","metadata":{"id":"OacxUyizS8d1"},"source":["#load weights of best model\n","path = 'saved_weights.pt'\n","model.load_state_dict(torch.load(path))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x4SVftkkTZXA"},"source":["# Get Predictions for Test Data"]},{"cell_type":"code","metadata":{"id":"NZl0SZmFTRQA"},"source":["# get predictions for test data\n","with torch.no_grad():\n","  preds = model(test_seq.to(device), test_mask.to(device))\n","  preds = preds.detach().cpu().numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ms1ObHZxTYSI"},"source":["# model's performance\n","preds = np.argmax(preds, axis = 1)\n","print(classification_report(test_y, preds))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YqzLS7rHTp4T"},"source":["# confusion matrix\n","# pd.crosstab(test_y, preds)\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","print(accuracy_score(test_y, preds))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jpX1uTwjUPY6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BY2P7H1W2Wo4"},"source":[""],"execution_count":null,"outputs":[]}]}