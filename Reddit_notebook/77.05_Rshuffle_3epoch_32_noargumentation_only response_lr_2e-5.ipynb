{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"77.05_Rshuffle_3epoch_32_noargumentation_only response_lr_2e-5.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OFOTiqrtNvyy"},"source":["# Install Transformers Library"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7sYuExU3YiR4","executionInfo":{"status":"ok","timestamp":1626437148330,"user_tz":420,"elapsed":407,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"6037fcac-720a-490d-9803-62bf1e7249c6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hkhc10wNrGt","executionInfo":{"status":"ok","timestamp":1626437152231,"user_tz":420,"elapsed":3228,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"3531a621-b8c6-4fce-da7e-91ff7d11f443"},"source":["!pip install transformers"],"execution_count":49,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4giRzM7NtHJ","executionInfo":{"status":"ok","timestamp":1626437152232,"user_tz":420,"elapsed":6,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import transformers\n","# from transformers import AutoModel, BertTokenizerFast\n","from transformers import RobertaTokenizer, RobertaModel\n","# specify GPU\n","device = torch.device(\"cuda\")"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":420},"id":"cwJrQFQgN_BE","executionInfo":{"status":"ok","timestamp":1626437153915,"user_tz":420,"elapsed":1688,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"f843a580-2b21-4046-af5b-bef04b050cb8"},"source":["# df = pd.read_json('/content/drive/MyDrive/sarcasm-detection/Datasets/reddit/sarcasm_detection_shared_task_reddit_training.jsonl',lines=True)\n","# df1 = pd.read_json('/content/drive/MyDrive/sarcasm-detection/Datasets/reddit/sarcasm_detection_shared_task_reddit_testing.jsonl',lines=True)\n","df = pd.read_json('/content/drive/MyDrive/sercasm/twitter/sarcasm_detection_shared_task_twitter_training.jsonl',lines=True)\n","df1 = pd.read_json('/content/drive/MyDrive/sercasm/twitter/sarcasm_detection_shared_task_twitter_testing.jsonl',lines=True)\n","df['labels'] = df['label'].apply(lambda x: ['SARCASM', 'NOT_SARCASM'].index(x))\n","df1['labels'] = df1['label'].apply(lambda x: ['SARCASM', 'NOT_SARCASM'].index(x))\n","df"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>response</th>\n","      <th>context</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n","      <td>[A minor child deserves privacy and should be ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER trying to protest about . Talking ...</td>\n","      <td>[@USER @USER Why is he a loser ? He's just a P...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER @USER He makes an insane about of ...</td>\n","      <td>[Donald J . Trump is guilty as charged . The e...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER Meanwhile Trump won't even release...</td>\n","      <td>[Jamie Raskin tanked Doug Collins . Collins lo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd...</td>\n","      <td>[Man ... y ‚Äô all gone ‚Äú both sides ‚Äù the apoca...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4995</th>\n","      <td>NOT_SARCASM</td>\n","      <td>@USER You don't . I have purchased a lot on Am...</td>\n","      <td>[@USER Apologies for the inconvenience you fac...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>NOT_SARCASM</td>\n","      <td>@USER #Emotions you say ü§î never knew that I th...</td>\n","      <td>[@USER ü§î idk tho , I think I ‚Äô m #hungry . But...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>NOT_SARCASM</td>\n","      <td>@USER @USER @USER You are so right ... \" Yes !...</td>\n","      <td>[@USER @USER @USER Peace to you , and two coun...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>NOT_SARCASM</td>\n","      <td>@USER @USER @USER Another lazy delusional vote...</td>\n","      <td>[Bernie Sanders told Elizabeth Warren in priva...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>NOT_SARCASM</td>\n","      <td>@USER @USER I hope you know no news outlet fro...</td>\n","      <td>[PDP PROTEST BRAINSTORMING SESSION Deji : We n...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows √ó 4 columns</p>\n","</div>"],"text/plain":["            label  ... labels\n","0         SARCASM  ...      0\n","1         SARCASM  ...      0\n","2         SARCASM  ...      0\n","3         SARCASM  ...      0\n","4         SARCASM  ...      0\n","...           ...  ...    ...\n","4995  NOT_SARCASM  ...      1\n","4996  NOT_SARCASM  ...      1\n","4997  NOT_SARCASM  ...      1\n","4998  NOT_SARCASM  ...      1\n","4999  NOT_SARCASM  ...      1\n","\n","[5000 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":420},"id":"HlJohUtOGoB_","executionInfo":{"status":"ok","timestamp":1626437153927,"user_tz":420,"elapsed":33,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"efcc4685-1812-4d5a-d298-386f301ed9d1"},"source":["df1"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>context</th>\n","      <th>response</th>\n","      <th>id</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NOT_SARCASM</td>\n","      <td>[Well now that ‚Äô s problematic AF &lt;URL&gt;, @USER...</td>\n","      <td>@USER @USER @USER My 3 year old , that just fi...</td>\n","      <td>twitter_1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SARCASM</td>\n","      <td>[Last week the Fake News said that a section o...</td>\n","      <td>@USER @USER How many verifiable lies has he to...</td>\n","      <td>twitter_2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>SARCASM</td>\n","      <td>[@USER Let ‚Äô s Aplaud Brett When he deserves i...</td>\n","      <td>@USER @USER @USER Maybe Docs just a scrub of a...</td>\n","      <td>twitter_3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NOT_SARCASM</td>\n","      <td>[Women generally hate this president . What's ...</td>\n","      <td>@USER @USER is just a cover up for the real ha...</td>\n","      <td>twitter_4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NOT_SARCASM</td>\n","      <td>[Dear media Remoaners , you excitedly sharing ...</td>\n","      <td>@USER @USER @USER The irony being that he even...</td>\n","      <td>twitter_5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1795</th>\n","      <td>NOT_SARCASM</td>\n","      <td>[I have been a business customer of MWeb @USER...</td>\n","      <td>@USER @USER @USER is definitely the best out t...</td>\n","      <td>twitter_1796</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1796</th>\n","      <td>SARCASM</td>\n","      <td>[A woman refuses to have her temperature taken...</td>\n","      <td>@USER @USER Ye let her out run wild and infect...</td>\n","      <td>twitter_1797</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1797</th>\n","      <td>SARCASM</td>\n","      <td>[The reason big government wants @USER out is ...</td>\n","      <td>@USER @USER @USER Thanks for that , I would ha...</td>\n","      <td>twitter_1798</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1798</th>\n","      <td>NOT_SARCASM</td>\n","      <td>[Happy #musicmonday and #thanks for #all your ...</td>\n","      <td>@USER @USER @USER Yes also #found this on #new...</td>\n","      <td>twitter_1799</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1799</th>\n","      <td>NOT_SARCASM</td>\n","      <td>[Not long wrapped on the amazing #January22nd ...</td>\n","      <td>@USER @USER @USER you still need to send the l...</td>\n","      <td>twitter_1800</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1800 rows √ó 5 columns</p>\n","</div>"],"text/plain":["            label  ... labels\n","0     NOT_SARCASM  ...      1\n","1         SARCASM  ...      0\n","2         SARCASM  ...      0\n","3     NOT_SARCASM  ...      1\n","4     NOT_SARCASM  ...      1\n","...           ...  ...    ...\n","1795  NOT_SARCASM  ...      1\n","1796      SARCASM  ...      0\n","1797      SARCASM  ...      0\n","1798  NOT_SARCASM  ...      1\n","1799  NOT_SARCASM  ...      1\n","\n","[1800 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"DIY6yOMr8sdX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626437159547,"user_tz":420,"elapsed":5648,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"a95d7c4a-009c-455e-c69e-4cbb46837698"},"source":["import pandas as pd\n","import re\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords\n","import re\n","import string\n","import numpy as np\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import TweetTokenizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from tqdm.auto import tqdm\n","!pip install demoji\n","!pip install contractions\n","import demoji\n","import contractions\n","from sklearn.utils import shuffle\n","\n","demoji.download_codes()\n","nltk.download('stopwords') \n","# nltk.download('wordnet')"],"execution_count":53,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: demoji in /usr/local/lib/python3.7/dist-packages (0.4.0)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from demoji) (0.4.4)\n","Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.7/dist-packages (from demoji) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (1.24.3)\n","Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.0.52)\n","Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n","Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.2.0)\n","Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n","Downloading emoji data ...\n","... OK (Got response in 0.13 seconds)\n","Writing emoji data to /root/.demoji/codes.json ...\n","... OK\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"Z5qBvDp14S4z","executionInfo":{"status":"ok","timestamp":1626437159548,"user_tz":420,"elapsed":6,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["def preprocess_text(text):\n","    # Tokenise words while ignoring punctuation(https://www.nltk.org/_modules/nltk/tokenize/regexp.html)\n","    text = re.sub(r\"@\",'', text)\n","    text = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', text)\n","    text = re.sub(r\"USER\",'@USER', text)\n","    text = re.sub(r'<URL>','',text)\n","\n","    text = demoji.replace_with_desc(text)\n","    text = re.sub(r':','',text)\n","    text = contractions.fix(text)\n","    # text = re.sub(r'\\.+','',text)\n","    return text"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nj-zpWUjt0IB","executionInfo":{"status":"ok","timestamp":1626437159548,"user_tz":420,"elapsed":5,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["def fun(A,l):\n","  if len(A)<=l:\n","    return A\n","  else:\n","    # return A[-l::1]\n","    return A[-1:-l-1:-1]\n","def fun1(A):\n","  return ''.join(A)"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3DFJt513x7X","executionInfo":{"status":"ok","timestamp":1626437165696,"user_tz":420,"elapsed":6152,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["l=0\n","\n","# df['tweets']= df['response'] +'reply-'+ df['context'].apply(fun,args=[l]).apply(fun1)\n","# df1['tweets']=df1['response'] +'reply-'+ df1['context'].apply(fun,args=[l]).apply(fun1)\n","\n","\n","\n","\n","df['tweets']= df['context'].apply(fun,args=[l]).apply(fun1) + df['response']\n","df1['tweets']= df1['context'].apply(fun,args=[l]).apply(fun1) + df1['response']\n","\n","\n","# df['tweets']= df['context'].apply(fun,args=[l]).apply(fun1) + df['response']\n","# df1['tweets']= df1['context'].apply(fun,args=[l]).apply(fun1) + df1['response']\n","\n","df['tweets']= df['tweets'].apply(preprocess_text) \n","df1['tweets']=df1['tweets'].apply(preprocess_text)\n","# df['tweets']=df['tweets']+'reply-'+ df['response'].apply(preprocess_text)\n","# df1['tweets']=df1['tweets']+'reply-'+ df1['response'].apply(preprocess_text)"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"676DPU1BOPdp","executionInfo":{"status":"ok","timestamp":1626437165697,"user_tz":420,"elapsed":39,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"1a68702b-9997-450b-9dfc-c17527177512"},"source":["# check class distribution\n","df['labels'].value_counts(normalize = True)"],"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    0.5\n","0    0.5\n","Name: labels, dtype: float64"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"mjLmL_LFtVjo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626437165698,"user_tz":420,"elapsed":33,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"376b01e7-2dd0-4b06-957b-2dea3fb54518"},"source":["df['tweets']"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       @USER I do not get this .. obviously you do ca...\n","1       @USER trying to protest about . Talking about ...\n","2       @USER He makes an insane about of money from t...\n","3       @USER Meanwhile Trump will not even release hi...\n","4       @USER Pretty Sure the Anti-Lincoln Crowd Claim...\n","                              ...                        \n","4995    @USER You do not . I have purchased a lot on A...\n","4996    @USER #Emotions you say thinking face never kn...\n","4997    @USER You are so right ... \" Yes ! #Silence is...\n","4998    @USER Another lazy delusional voter who takes ...\n","4999    @USER I hope you know no news outlet from Nige...\n","Name: tweets, Length: 5000, dtype: object"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"WRcHuf9XdkWK","executionInfo":{"status":"ok","timestamp":1626437165699,"user_tz":420,"elapsed":20,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["# df=shuffle(df,random_state=42)"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"3snQJjMYeHA-","executionInfo":{"status":"ok","timestamp":1626437165700,"user_tz":420,"elapsed":20,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"3c8a04e4-0e74-43e8-c713-c21c5f103486"},"source":["df1.head()"],"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>context</th>\n","      <th>response</th>\n","      <th>id</th>\n","      <th>labels</th>\n","      <th>tweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NOT_SARCASM</td>\n","      <td>[Well now that ‚Äô s problematic AF &lt;URL&gt;, @USER...</td>\n","      <td>@USER @USER @USER My 3 year old , that just fi...</td>\n","      <td>twitter_1</td>\n","      <td>1</td>\n","      <td>@USER My 3 year old , that just finished readi...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SARCASM</td>\n","      <td>[Last week the Fake News said that a section o...</td>\n","      <td>@USER @USER How many verifiable lies has he to...</td>\n","      <td>twitter_2</td>\n","      <td>0</td>\n","      <td>@USER How many verifiable lies has he told now...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>SARCASM</td>\n","      <td>[@USER Let ‚Äô s Aplaud Brett When he deserves i...</td>\n","      <td>@USER @USER @USER Maybe Docs just a scrub of a...</td>\n","      <td>twitter_3</td>\n","      <td>0</td>\n","      <td>@USER Maybe Docs just a scrub of a coach ... I...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NOT_SARCASM</td>\n","      <td>[Women generally hate this president . What's ...</td>\n","      <td>@USER @USER is just a cover up for the real ha...</td>\n","      <td>twitter_4</td>\n","      <td>1</td>\n","      <td>@USER is just a cover up for the real hate ins...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NOT_SARCASM</td>\n","      <td>[Dear media Remoaners , you excitedly sharing ...</td>\n","      <td>@USER @USER @USER The irony being that he even...</td>\n","      <td>twitter_5</td>\n","      <td>1</td>\n","      <td>@USER The irony being that he even has to ask ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         label  ...                                             tweets\n","0  NOT_SARCASM  ...  @USER My 3 year old , that just finished readi...\n","1      SARCASM  ...  @USER How many verifiable lies has he told now...\n","2      SARCASM  ...  @USER Maybe Docs just a scrub of a coach ... I...\n","3  NOT_SARCASM  ...  @USER is just a cover up for the real hate ins...\n","4  NOT_SARCASM  ...  @USER The irony being that he even has to ask ...\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"markdown","metadata":{"id":"MKfWnApvOoE7"},"source":["# Split train dataset into train, validation and test sets"]},{"cell_type":"code","metadata":{"id":"mfhSPF5jOWb7","executionInfo":{"status":"ok","timestamp":1626437165701,"user_tz":420,"elapsed":20,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["\n","X_s = df['tweets'].values\n","y_s = df['labels'].values\n","\n","Xt_s = df1['tweets'].values\n","yt_s = df1['labels'].values\n","\n","train_text, temp_text, train_labels, temp_labels = X_s,Xt_s,y_s,yt_s\n","\n","# we will use temp_text and temp_labels to create validation and test set\n","# val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n","#                                                                 random_state=2018, \n","#                                                                 test_size=0.5, \n","#                                                                 stratify=temp_labels)\n","val_text, test_text, val_labels, test_labels=temp_text, temp_text, temp_labels, temp_labels\n","\n","# X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.2, random_state=42)\n"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQ5fFgPHG7pW","executionInfo":{"status":"ok","timestamp":1626437165701,"user_tz":420,"elapsed":19,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"9af03eba-6a12-41a5-e166-33df56fbd720"},"source":["print(X_s)"],"execution_count":62,"outputs":[{"output_type":"stream","text":["['@USER I do not get this .. obviously you do care or you would have moved right along .. instead you decided to care and troll her ..'\n"," '@USER trying to protest about . Talking about him and his labels and they label themselves WTF does that make them ?'\n"," '@USER He makes an insane about of money from the MOVIES , Einstein ! #LearnHowTheSystemWorks'\n"," ...\n"," '@USER You are so right ... \" Yes ! #Silence is not #Privacy is not \"'\n"," '@USER Another lazy delusional voter who takes the word of corporatists at face value , instead of doing research & finding out s / he ‚Äô s being lied to'\n"," '@USER I hope you know no news outlet from Nigeria have said a thing about the Luxurious buss ( from sokoto goint to East ) passengers kidnapped by ARMED men on Teusday in Kaduna ? Among them is one of your former neighbor .']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W1jEFb39cCjk","executionInfo":{"status":"ok","timestamp":1626437165702,"user_tz":420,"elapsed":14,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["# pip install -U sentence-transformers"],"execution_count":63,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n7hsdLoCO7uB"},"source":["# Import BERT Model and BERT Tokenizer\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S1kY3gZjO2RE","executionInfo":{"status":"ok","timestamp":1626437169857,"user_tz":420,"elapsed":4168,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"1334e9a4-87a0-4c27-e071-f68e811ba875"},"source":["# import BERT-base pretrained model\n","# bert = AutoModel.from_pretrained('bert-base-uncased')\n","\n","# # Load the BERT tokenizer\n","# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","# import BERT-base pretrained model\n","\n","\n","# from transformers import RobertaTokenizer, TFRobertaModel\n","# bert = RobertaModel.from_pretrained('roberta-base')\n","\n","# # Load the BERT tokenizer\n","# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","\n","from transformers import RobertaTokenizer, TFRobertaModel\n","bert = RobertaModel.from_pretrained('roberta-large')\n","\n","# Load the BERT tokenizer\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-large')"],"execution_count":64,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_zOKeOMeO-DT","executionInfo":{"status":"ok","timestamp":1626437169857,"user_tz":420,"elapsed":22,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["# sample data\n","text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n","# encode text\n","sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oAH73n39PHLw","executionInfo":{"status":"ok","timestamp":1626437169858,"user_tz":420,"elapsed":21,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"0952f35d-f883-417d-d182-1dc41e675982"},"source":["# output\n","print(sent_id)"],"execution_count":66,"outputs":[{"output_type":"stream","text":["{'input_ids': [[0, 9226, 16, 10, 741, 2399, 1421, 35950, 2, 1, 1, 1], [0, 1694, 40, 2051, 12, 90, 4438, 10, 741, 2399, 1421, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8wIYaWI_Prg8"},"source":["# Tokenization"]},{"cell_type":"code","metadata":{"id":"yKwbpeN_PMiu","executionInfo":{"status":"ok","timestamp":1626437169859,"user_tz":420,"elapsed":18,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["# # get length of all the messages in the train set\n","# seq_len = [len(i.split()) for i in train_text]\n","# for i in train_text:\n","#   print(i)\n","# pd.Series(seq_len).hist(bins = 30)"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXcswEIRPvGe","executionInfo":{"status":"ok","timestamp":1626437169859,"user_tz":420,"elapsed":18,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["# max_seq_len = 190\n","# max_seq_len = 128\n","max_seq_len = 120\n"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"id":"hGcvb0cV5irf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626437169860,"user_tz":420,"elapsed":18,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"91bd7b22-95cf-4c1b-ce23-37fcb47270f5"},"source":["total=0\n","for i in range(4400):\n","  total+=len(df['tweets'][i].split(' '))\n","total/4400"],"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["26.52090909090909"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tk5S7DWaP2t6","executionInfo":{"status":"ok","timestamp":1626437173228,"user_tz":420,"elapsed":3382,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"1d4b76c7-5cdd-4f90-c042-718b5322ac60"},"source":["# tokenize and encode sequences in the training set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")"],"execution_count":70,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zhYavNEiHrPt","executionInfo":{"status":"ok","timestamp":1626437173229,"user_tz":420,"elapsed":34,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"1733d7a2-c229-4139-f15a-c43d748853a9"},"source":["train_text"],"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['@USER I do not get this .. obviously you do care or you would have moved right along .. instead you decided to care and troll her ..',\n","       '@USER trying to protest about . Talking about him and his labels and they label themselves WTF does that make them ?',\n","       '@USER He makes an insane about of money from the MOVIES , Einstein ! #LearnHowTheSystemWorks',\n","       ...,\n","       '@USER You are so right ... \" Yes ! #Silence is not #Privacy is not \"',\n","       '@USER Another lazy delusional voter who takes the word of corporatists at face value , instead of doing research & finding out s / he ‚Äô s being lied to',\n","       '@USER I hope you know no news outlet from Nigeria have said a thing about the Luxurious buss ( from sokoto goint to East ) passengers kidnapped by ARMED men on Teusday in Kaduna ? Among them is one of your former neighbor .'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"markdown","metadata":{"id":"Wsm8bkRZQTw9"},"source":["# Convert Integer Sequences to Tensors"]},{"cell_type":"code","metadata":{"id":"QR-lXwmzQPd6","executionInfo":{"status":"ok","timestamp":1626437173229,"user_tz":420,"elapsed":25,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["# for train set\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","# for validation set\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","# for test set\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"],"execution_count":72,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-r_r1WoH33P","executionInfo":{"status":"ok","timestamp":1626437173230,"user_tz":420,"elapsed":24,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"aa901a01-671f-42ac-9bac-c5ee9a6e5532"},"source":["train_seq"],"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[    0,  1039, 47955,  ...,     1,     1,     1],\n","        [    0,  1039, 47955,  ...,     1,     1,     1],\n","        [    0,  1039, 47955,  ...,     1,     1,     1],\n","        ...,\n","        [    0,  1039, 47955,  ...,     1,     1,     1],\n","        [    0,  1039, 47955,  ...,     1,     1,     1],\n","        [    0,  1039, 47955,  ...,     1,     1,     1]])"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"markdown","metadata":{"id":"Ov1cOBlcRLuk"},"source":["# Create DataLoaders"]},{"cell_type":"code","metadata":{"id":"qUy9JKFYQYLp","executionInfo":{"status":"ok","timestamp":1626437173231,"user_tz":420,"elapsed":15,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","#define a batch size\n","batch_size = 32\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"],"execution_count":74,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K2HZc5ZYRV28"},"source":["# Freeze BERT Parameters"]},{"cell_type":"code","metadata":{"id":"wHZ0MC00RQA_","executionInfo":{"status":"ok","timestamp":1626437173231,"user_tz":420,"elapsed":13,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["# freeze all the parameters\n","for param in bert.parameters():\n","    param.requires_grad = True\n","# print(bert)"],"execution_count":75,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s7ahGBUWRi3X"},"source":["# Define Model Architecture"]},{"cell_type":"code","metadata":{"id":"b3iEtGyYRd0A","executionInfo":{"status":"ok","timestamp":1626437173232,"user_tz":420,"elapsed":13,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, bert):\n","      \n","      super(BERT_Arch, self).__init__()\n","\n","      self.bert = bert \n","      \n","      # dropout layer\n","      self.dropout = nn.Dropout(0.25)\n","      \n","      # relu activation function\n","      self.relu =  nn.ReLU()\n","\n","      # dense layer 1\n","      # self.fc1 = nn.Linear(768,256)\n","      self.fc1 = nn.Linear(1024,256)\n","      # dense layer 2 (Output layer)\n","      self.fc2 = nn.Linear(256,2)\n","\n","      #softmax activation function\n","      self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","\n","      #pass the inputs to the model  \n","      _, cls_hs = self.bert(sent_id,mask, return_dict=False)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn11111 \",cls_hs.shape)\n","      x = self.fc1(cls_hs)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      x = self.relu(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      x = self.dropout(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      # output layer\n","      x = self.fc2(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      # apply softmax activation\n","      x = self.softmax(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      return x"],"execution_count":76,"outputs":[]},{"cell_type":"code","metadata":{"id":"cBAJJVuJRliv","executionInfo":{"status":"ok","timestamp":1626437174132,"user_tz":420,"elapsed":911,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(bert)\n","\n","# push the model to GPU\n","model = model.to(device)"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"taXS0IilRn9J","executionInfo":{"status":"ok","timestamp":1626437174133,"user_tz":420,"elapsed":40,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = AdamW(model.parameters(), lr = 2e-5)"],"execution_count":78,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j9CDpoMQR_rK"},"source":["# Find Class Weights"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"izY5xH5eR7Ur","executionInfo":{"status":"ok","timestamp":1626437174133,"user_tz":420,"elapsed":37,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"e0cd51ec-9542-433c-89f9-9eeb1a1e78c6"},"source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","#compute the class weights\n","class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n","\n","print(class_wts)"],"execution_count":79,"outputs":[{"output_type":"stream","text":["[1. 1.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r1WvfY2vSGKi","executionInfo":{"status":"ok","timestamp":1626437174134,"user_tz":420,"elapsed":33,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","cross_entropy  = nn.NLLLoss(weight=weights) \n","\n","# number of training epochs\n","epochs = 10"],"execution_count":80,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"My4CA0qaShLq"},"source":["# Fine-Tune BERT"]},{"cell_type":"code","metadata":{"id":"rskLk8R_SahS","executionInfo":{"status":"ok","timestamp":1626437174134,"user_tz":420,"elapsed":31,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["# function to train the model\n","def train():\n","  \n","  model.train()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save model predictions\n","  total_preds=[]\n","  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):\n","    \n","    # progress update after every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n"," \n","    sent_id, mask, labels = batch\n","\n","    # clear previously calculated gradients \n","    model.zero_grad()        \n","\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask)\n","\n","    # compute the loss between actual and predicted values\n","    loss = cross_entropy(preds, labels)\n","\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    # update parameters\n","    optimizer.step()\n","\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)\n","  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"id":"yGXovFDlSxB5","executionInfo":{"status":"ok","timestamp":1626437174135,"user_tz":420,"elapsed":28,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["# function for evaluating the model\n","def evaluate():\n","  \n","  print(\"\\nEvaluating...\")\n","  \n","  # deactivate dropout layers\n","  model.eval()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save the model predictions\n","  total_preds = []\n","\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):\n","    \n","    # Progress update every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      \n","      # Calculate elapsed time in minutes.\n","      # elapsed = format_time(time.time() - t0)\n","            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","\n","    sent_id, mask, labels = batch\n","\n","    # deactivate autograd\n","    with torch.no_grad():\n","      \n","      # model predictions\n","      preds = model(sent_id, mask)\n","\n","      # compute the validation loss between actual and predicted values\n","      loss = cross_entropy(preds,labels)\n","\n","      total_loss = total_loss + loss.item()\n","\n","      preds = preds.detach().cpu().numpy()\n","\n","      total_preds.append(preds)\n","\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  return avg_loss, total_preds"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"id":"WHQlio6yM_QH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626437174135,"user_tz":420,"elapsed":26,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"1558a692-36b5-42ce-d359-fdc4c94f9f8f"},"source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","!nvidia-smi"],"execution_count":83,"outputs":[{"output_type":"stream","text":["Fri Jul 16 12:06:18 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   74C    P0    32W /  70W |  15092MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9KZEgxRRTLXG"},"source":["# Start Model Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"k1USGTntS3TS","executionInfo":{"status":"error","timestamp":1626437773178,"user_tz":420,"elapsed":424,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"a97d8bce-fedd-484d-c9d9-809315f13e99"},"source":["# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","#for each epoch\n","epochs=1\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss,_ = train()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    #save the best model\n","    # if valid_loss < best_valid_loss:\n","    best_valid_loss = valid_loss\n","    torch.save(model.state_dict(), 'saved_weights.pt')\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","  \n","    # get predictions for test data\n","    # !nvidia-smi\n","    # with torch.no_grad():\n","    0.\n","    #   preds = model(test_seq.to(device), test_mask.to(device))\n","    #   preds = preds.detach().cpu().numpy()\n","    # preds = np.argmax(preds, axis = 1)\n","    # print(classification_report(test_y, preds))\n","    # print(accuracy_score(test_y, preds))\n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"execution_count":96,"outputs":[{"output_type":"stream","text":["\n"," Epoch 1 / 1\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-96-edc570ae70a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-81-a8875e82e2a3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# get model predictions for the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# compute the loss between actual and predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-76-898cc930df21>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m       \u001b[0;31m# print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn11111 \",cls_hs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m         )\n\u001b[1;32m    835\u001b[0m         encoder_outputs = self.encoder(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.76 GiB total capacity; 13.39 GiB already allocated; 3.75 MiB free; 13.69 GiB reserved in total by PyTorch)"]}]},{"cell_type":"markdown","metadata":{"id":"_yrhUc9kTI5a"},"source":["# Load Saved Model"]},{"cell_type":"code","metadata":{"id":"OacxUyizS8d1","executionInfo":{"status":"aborted","timestamp":1626437679562,"user_tz":420,"elapsed":19,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["#load weights of best model\n","path = 'saved_weights.pt'\n","model.load_state_dict(torch.load(path))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x4SVftkkTZXA"},"source":["# Get Predictions for Test Data"]},{"cell_type":"code","metadata":{"id":"NZl0SZmFTRQA","executionInfo":{"status":"aborted","timestamp":1626437679563,"user_tz":420,"elapsed":19,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["pred=[]\n","with torch.no_grad():\n","  for i in range(0,90):\n","    preds = model(test_seq[i*20:i*20+20].to(device), test_mask[i*20:i*20+20].to(device))\n","    preds = preds.detach().cpu().numpy()\n","    pred.append(preds)\n","print(np.array(pred).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YS9jf3NEqM3H","executionInfo":{"status":"aborted","timestamp":1626437679566,"user_tz":420,"elapsed":22,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["pred1=np.array(pred)\n","# pred1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I1b4nLmzqOaY","executionInfo":{"status":"aborted","timestamp":1626437679567,"user_tz":420,"elapsed":23,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["pred2=pred1.reshape((1800,2))\n","pred2.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQ_1m2WhgL7k","executionInfo":{"status":"aborted","timestamp":1626437679568,"user_tz":420,"elapsed":24,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["p=pd.DataFrame(pred2)\n","p.to_csv('Rshuffle_5epoch.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d8su6xM8gSNJ","executionInfo":{"status":"aborted","timestamp":1626437679569,"user_tz":420,"elapsed":24,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["pred3 = np.argmax(pred2, axis = 1)\n","pred3 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZMw2NRnngSQs","executionInfo":{"status":"aborted","timestamp":1626437679570,"user_tz":420,"elapsed":25,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["print(classification_report(test_y, pred3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5K4dl1AQgShx","executionInfo":{"status":"aborted","timestamp":1626437679570,"user_tz":420,"elapsed":25,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["# confusion matrix\n","# print(pred)\n","pd.crosstab(test_y, pred3)\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","print(accuracy_score(test_y, pred3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vIOKI7dNei5x","executionInfo":{"status":"aborted","timestamp":1626437679571,"user_tz":420,"elapsed":26,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W14537b4ubb6","executionInfo":{"status":"aborted","timestamp":1626437679572,"user_tz":420,"elapsed":26,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["import scipy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G0psIEgeubdz","executionInfo":{"status":"aborted","timestamp":1626437679573,"user_tz":420,"elapsed":27,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["brcc=pd.read_csv('76.6_roberta_large_100_32_2e-5_4epoch_preprocessing+@reply+user.csv')\n","brcc=np.array(brcc[['0','1']])\n","brcc=scipy.special.softmax(brcc,axis=1)\n","# bsvm=np.multiply(bsvm,-1)\n","brcc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1eyDGkYuubhK","executionInfo":{"status":"aborted","timestamp":1626437679574,"user_tz":420,"elapsed":28,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["brc=pd.read_csv('77.44_1context+response_batch16+3epoch_180maxlen.csv')\n","brc=np.array(brc[['0','1']])\n","brc=scipy.special.softmax(brc,axis=1)\n","# bsvm=np.multiply(bsvm,-1)\n","brc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ms1ObHZxTYSI","executionInfo":{"status":"aborted","timestamp":1626437679574,"user_tz":420,"elapsed":29,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["br=pd.read_csv('77.7_2context+response_batch16+4epoch_190maxlen.csv')\n","br=np.array(br[['0','1']])\n","br=scipy.special.softmax(br,axis=1)\n","# bsvm=np.multiply(bsvm,-1)\n","br"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YqzLS7rHTp4T","executionInfo":{"status":"aborted","timestamp":1626437679575,"user_tz":420,"elapsed":28,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["bc=pd.read_csv('76.56_2context_+response_temserflow.csv')\n","bc=np.array(bc[['0','1']])\n","bc=scipy.special.softmax(bc,axis=1)\n","# bsvm=np.multiply(bsvm,-1)\n","bc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0_HPa0uXH6he","executionInfo":{"status":"aborted","timestamp":1626437679576,"user_tz":420,"elapsed":29,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["bkc=pd.read_csv('75_lstm_base_response.csv')\n","bkc=np.array(bkc[['0','1']])\n","bkc=scipy.special.softmax(bkc,axis=1)\n","# bsvm=np.multiply(bsvm,-1)\n","bkc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jpX1uTwjUPY6","executionInfo":{"status":"aborted","timestamp":1626437679578,"user_tz":420,"elapsed":31,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["# bertc=np.array(bc[['0','1']])\n","bertc1=np.multiply(bc,0.6)\n","\n","# bertrcc=np.array(brcc[['0','1']])\n","bertrcc1=np.multiply(brcc,0.8)\n","\n","# bertcr=np.array(brc[['0','1']])\n","bertcr1=np.multiply(brc,0.6)\n","\n","# bertr=np.array(br[['0','1']])\n","bertr1=np.multiply(br,0.45)\n","\n","\n","\n","# # bertc=np.array(bc[['0','1']])\n","# bertc1=np.multiply(bc,0.4)\n","\n","# # bertrcc=np.array(brcc[['0','1']])\n","# bertrcc1=np.multiply(brcc,0.8)\n","\n","# # bertcr=np.array(brc[['0','1']])\n","# bertcr1=np.multiply(brc,0.4)\n","\n","# bertr=np.array(br[['0','1']])\n","# bertr1=np.multiply(br,0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BY2P7H1W2Wo4","executionInfo":{"status":"aborted","timestamp":1626437679578,"user_tz":420,"elapsed":31,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["yhats = [bertc1,bertr1,bertcr1,bertrcc1]\n","# yhats = [bertcr1,bertrcc1,bertr1]\n","# yhats = [bertcr1,bertrcc1,bertr1]\n","# import numpy as np\n","# yhats = np.array(yhats)\n","\n","# # sum across ensemble members\n","# summed = np.sum(yhats, axis=0)\n","# # argmax across classes\n","# result = np.argmax(summed, axis=1)\n","\n","# from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","# accuracy_score(result,test_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"33vNifQf_Ojz","executionInfo":{"status":"aborted","timestamp":1626437679579,"user_tz":420,"elapsed":31,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}}},"source":["ans=[]\n","yhat=[bc,br,brcc,brc,bkc]\n","# yhat=[brcc,br,brc]\n","for i in yhat:\n","  ans.append(np.argmax(i, axis=1))\n","summed = np.sum(ans, axis=0)/4\n","res=[]\n","for i in summed:\n","  if i<=0.5:\n","    res.append(0)\n","  else:\n","    res.append(1)\n","\n","print(res)\n","\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","# accuracy_score(res,test_y)\n","\n","\n","print(classification_report(test_y, res))\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","print(accuracy_score(test_y, res))"],"execution_count":null,"outputs":[]}]}