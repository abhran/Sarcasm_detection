{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of robertra_29_06_bert_context","provenance":[{"file_id":"1vJm89K5GifSBrgk13JUA_9L_ijaynqu1","timestamp":1624448853836},{"file_id":"1SaLnCHSb6TrMEFtSK8DQ00RXaH7roO2W","timestamp":1624439603375},{"file_id":"1ftGKQ22ZBSIX_d6KEpUI7vRczYgtQPMF","timestamp":1620983839237},{"file_id":"https://github.com/prateekjoshi565/Fine-Tuning-BERT/blob/master/Fine_Tuning_BERT_for_Spam_Classification.ipynb","timestamp":1619947106006}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"181d7dd797544ef688d6ef848e873976":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_333a3069022244649f3c035316059996","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8fd2e6b9c424495ca46af062b648929d","IPY_MODEL_dee99927ee194dec8dd0487fa0eacb59"]}},"333a3069022244649f3c035316059996":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8fd2e6b9c424495ca46af062b648929d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_36cdbc13d8104dc494626c15d70b17b7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":482,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":482,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_71423e3ba42a4b7595a680f9e8160a15"}},"dee99927ee194dec8dd0487fa0eacb59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fd529bfd6a9e493d8b78736c071e0c48","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 482/482 [00:38&lt;00:00, 12.4B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ba261e6aac24faeb392150a49992e02"}},"36cdbc13d8104dc494626c15d70b17b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"71423e3ba42a4b7595a680f9e8160a15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd529bfd6a9e493d8b78736c071e0c48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4ba261e6aac24faeb392150a49992e02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ae82cb237b2419a925e60de3773dc06":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a0d89738c20446689d2701b83f7b2518","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f93a5c4c3cf34b3e863597e59a572a98","IPY_MODEL_6ed8b93834da4eb8a0d833641611e051"]}},"a0d89738c20446689d2701b83f7b2518":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f93a5c4c3cf34b3e863597e59a572a98":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_19266f44451544949f2b2849bd218282","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1425941629,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1425941629,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_020da278d8b04e16929eb633c731f814"}},"6ed8b93834da4eb8a0d833641611e051":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_88e71ec7da3247e19ce72c66713449bb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.43G/1.43G [00:38&lt;00:00, 37.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f9c570d5fcc64be0b34c1e36978c939f"}},"19266f44451544949f2b2849bd218282":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"020da278d8b04e16929eb633c731f814":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88e71ec7da3247e19ce72c66713449bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f9c570d5fcc64be0b34c1e36978c939f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d87c16b145d4c03bd3701458e213d93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aae31e9253544a1f9dfd87cfcebad67f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_513d872c5dd5408bacd33c174955c10a","IPY_MODEL_b92c23f479a34dd8946710a622dea415"]}},"aae31e9253544a1f9dfd87cfcebad67f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"513d872c5dd5408bacd33c174955c10a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_42fcb95f09894cef96bf60d29d1f6e38","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_488c95ab73f144209ed0a42f32bdd7ad"}},"b92c23f479a34dd8946710a622dea415":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4fec74fc0aba4261aa3f18c35912a9bb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:01&lt;00:00, 783kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_37c3cb7c989f48e79b0393bb56e13c05"}},"42fcb95f09894cef96bf60d29d1f6e38":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"488c95ab73f144209ed0a42f32bdd7ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4fec74fc0aba4261aa3f18c35912a9bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"37c3cb7c989f48e79b0393bb56e13c05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ef25fafcb784f97ad3a56c4551d508b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1428514a052948e9865b46661db72c9c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4a122bee9d7f4461b6d458500da336c5","IPY_MODEL_f4d8dd72184f43019e08f0cccfa447b1"]}},"1428514a052948e9865b46661db72c9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a122bee9d7f4461b6d458500da336c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4a7fe91bce1f40a7ac191af5a2ca24f2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7c55fc79576649b7b2315be211dba7dd"}},"f4d8dd72184f43019e08f0cccfa447b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_933842e451ac4a0b9b7fd220286fd2b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 592kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fa154cbc310d4b2e90704e55f553e583"}},"4a7fe91bce1f40a7ac191af5a2ca24f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7c55fc79576649b7b2315be211dba7dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"933842e451ac4a0b9b7fd220286fd2b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fa154cbc310d4b2e90704e55f553e583":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31df8c760c704bd78a12c0abcf4e9ae0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_320b935363084e97ab74dfaddb2abc39","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9acc1b770f4c4f8aa96ce6bd434a0840","IPY_MODEL_e06344f6da984b60a6515f8ae88f09b1"]}},"320b935363084e97ab74dfaddb2abc39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9acc1b770f4c4f8aa96ce6bd434a0840":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c2d289a32d0445b0bee4a63b8314dfef","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_793eecdfbd2141d4992197f3ede3ce80"}},"e06344f6da984b60a6515f8ae88f09b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2baa6d6992af4a54a3209040705b47ba","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:00&lt;00:00, 7.20MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_03d61ce22207452da05ef76aa365bc4a"}},"c2d289a32d0445b0bee4a63b8314dfef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"793eecdfbd2141d4992197f3ede3ce80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2baa6d6992af4a54a3209040705b47ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"03d61ce22207452da05ef76aa365bc4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"OFOTiqrtNvyy"},"source":["# Install Transformers Library"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IfUBJLufrKqn","executionInfo":{"status":"ok","timestamp":1626418616221,"user_tz":420,"elapsed":18583,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"1a5e5b04-ee74-4d54-9d3f-de33610e0b0e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hkhc10wNrGt","executionInfo":{"status":"ok","timestamp":1626418624421,"user_tz":420,"elapsed":8211,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"2f942294-d085-4270-93c4-77d94dbbc17d"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 5.3MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 33.5MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.12\n","  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 41.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.5.0)\n","Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n","Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4giRzM7NtHJ"},"source":["import numpy as np\n","import pandas as pd\n","# import torch\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import transformers\n","# from transformers import AutoModel, BertTokenizerFast\n","from transformers import RobertaTokenizer, RobertaModel,RobertaForSequenceClassification\n","# specify GPU\n","# device = torch.device(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"cwJrQFQgN_BE","executionInfo":{"status":"ok","timestamp":1626418655220,"user_tz":420,"elapsed":1921,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"98a69bce-1170-4d74-fdf5-d71b7eb96d59"},"source":["df1 = pd.read_json('/content/drive/MyDrive/sarcasm-detection/Datasets/twitter/sarcasm_detection_shared_task_twitter_testing.jsonl',lines=True)\n","df = pd.read_json('/content/drive/MyDrive/sarcasm-detection/Datasets/twitter/sarcasm_detection_shared_task_twitter_training.jsonl',lines=True)\n","\n","df['labels'] = df['label'].apply(lambda x: ['SARCASM', 'NOT_SARCASM'].index(x))\n","df1['labels'] = df1['label'].apply(lambda x: ['SARCASM', 'NOT_SARCASM'].index(x))\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>response</th>\n","      <th>context</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n","      <td>[A minor child deserves privacy and should be ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER trying to protest about . Talking ...</td>\n","      <td>[@USER @USER Why is he a loser ? He's just a P...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER @USER He makes an insane about of ...</td>\n","      <td>[Donald J . Trump is guilty as charged . The e...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER Meanwhile Trump won't even release...</td>\n","      <td>[Jamie Raskin tanked Doug Collins . Collins lo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd...</td>\n","      <td>[Man ... y ’ all gone “ both sides ” the apoca...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     label  ... labels\n","0  SARCASM  ...      0\n","1  SARCASM  ...      0\n","2  SARCASM  ...      0\n","3  SARCASM  ...      0\n","4  SARCASM  ...      0\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1CpQxLslJlNv","executionInfo":{"status":"ok","timestamp":1626418671690,"user_tz":420,"elapsed":12375,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"41569a43-e9cf-436e-d7e8-c0eab961244f"},"source":["import pandas as pd\n","import re\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords\n","import re\n","import string\n","import numpy as np\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import TweetTokenizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from tqdm.auto import tqdm\n","!pip install demoji\n","!pip install contractions\n","import demoji\n","import contractions\n","\n","demoji.download_codes()\n","nltk.download('stopwords') \n","# nltk.download('wordnet')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting demoji\n","  Downloading https://files.pythonhosted.org/packages/88/6a/34379abe01c9c36fe9fddc4181dd935332e7d0159ec3fae76f712e49bcea/demoji-0.4.0-py2.py3-none-any.whl\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.7/dist-packages (from demoji) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (2021.5.30)\n","Installing collected packages: colorama, demoji\n","Successfully installed colorama-0.4.4 demoji-0.4.0\n","Collecting contractions\n","  Downloading https://files.pythonhosted.org/packages/93/f4/0ec4a458e4368cc3be2c799411ecf0bc961930e566dadb9624563821b3a6/contractions-0.0.52-py2.py3-none-any.whl\n","Collecting textsearch>=0.0.21\n","  Downloading https://files.pythonhosted.org/packages/d3/fe/021d7d76961b5ceb9f8d022c4138461d83beff36c3938dc424586085e559/textsearch-0.0.21-py2.py3-none-any.whl\n","Collecting anyascii\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/14/666cd44bf53f36a961544af592cb5c5c800013f9c51a4745af8d7c17362a/anyascii-0.2.0-py3-none-any.whl (283kB)\n","\u001b[K     |████████████████████████████████| 286kB 5.3MB/s \n","\u001b[?25hCollecting pyahocorasick\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/c2/eae730037ae1cbbfaa229d27030d1d5e34a1e41114b21447d1202ae9c220/pyahocorasick-1.4.2.tar.gz (321kB)\n","\u001b[K     |████████████████████████████████| 327kB 41.1MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n","  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85397 sha256=cd6a08d994d0e01a3ac49176dfbe405738111520adae6d526dc7caf1c624fda0\n","  Stored in directory: /root/.cache/pip/wheels/3a/03/34/77e3ece0bba8b86bfac88a79f923b36d805cad63caeba38842\n","Successfully built pyahocorasick\n","Installing collected packages: anyascii, pyahocorasick, textsearch, contractions\n","Successfully installed anyascii-0.2.0 contractions-0.0.52 pyahocorasick-1.4.2 textsearch-0.0.21\n","Downloading emoji data ...\n","... OK (Got response in 0.14 seconds)\n","Writing emoji data to /root/.demoji/codes.json ...\n","... OK\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"Z5qBvDp14S4z"},"source":["def preprocess_text(text):\n","    # Tokenise words while ignoring punctuation(https://www.nltk.org/_modules/nltk/tokenize/regexp.html)\n","    text = re.sub(r\"@\",'', text)\n","    text = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', text)\n","    text = re.sub(r\"USER\",'@USER', text)\n","    text = re.sub(r'<URL>','',text)\n","\n","    text = demoji.replace_with_desc(text)\n","    text = re.sub(r':','',text)\n","    text = contractions.fix(text)\n","    # text = re.sub(r'\\.+','',text)\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kbn2PHEb428M","executionInfo":{"status":"ok","timestamp":1626418671691,"user_tz":420,"elapsed":18,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"6b409f1f-f263-4a9e-adf6-f323bf0ab871"},"source":["for i in range(5):\n","  print(df['response'][i])\n","  print(preprocess_text(df['response'][i]))\n","  # print(preprocess_text2(df['response'][i]))\n","  print()\n","  # print(df['context_resp'][i])\n","  # print(preprocess_text(df['context_resp'][i]))\n","  # print(preprocess_text2(df['context_resp'][i]))\n","  # print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["@USER @USER @USER I don't get this .. obviously you do care or you would've moved right along .. instead you decided to care and troll her ..\n","@USER I do not get this .. obviously you do care or you would have moved right along .. instead you decided to care and troll her ..\n","\n","@USER @USER trying to protest about . Talking about him and his labels and they label themselves WTF does that make em ?\n","@USER trying to protest about . Talking about him and his labels and they label themselves WTF does that make them ?\n","\n","@USER @USER @USER He makes an insane about of money from the MOVIES , Einstein ! #LearnHowTheSystemWorks\n","@USER He makes an insane about of money from the MOVIES , Einstein ! #LearnHowTheSystemWorks\n","\n","@USER @USER Meanwhile Trump won't even release his SAT scores and his Wharton professors said he was the dumbest student they've ever taught\n","@USER Meanwhile Trump will not even release his SAT scores and his Wharton professors said he was the dumbest student they have ever taught\n","\n","@USER @USER Pretty Sure the Anti-Lincoln Crowd Claimed That \" Democracy Was on the Ballot \" in 1860 , too . They Thought Lincoln Was \" Authoritarian \" . #GOP #PartyOfLincoln #Democrats\n","@USER Pretty Sure the Anti-Lincoln Crowd Claimed That \" Democracy Was on the Ballot \" in 1860 , too . They Thought Lincoln Was \" Authoritarian \" . #GOP #PartyOfLincoln #Democrats\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nj-zpWUjt0IB"},"source":["def fun(A,l):\n","  if len(A)<=l:\n","    return A\n","  else:\n","    # return A[-l::1]\n","    return A[-1:-l-1:-1]\n","def fun1(A):\n","  return ''.join(A)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3DFJt513x7X"},"source":["l=0\n","\n","# df['tweets']= df['response'] +'reply-'+ df['context'].apply(fun,args=[l]).apply(fun1)\n","# df1['tweets']=df1['response'] +'reply-'+ df1['context'].apply(fun,args=[l]).apply(fun1)\n","df['tweets']= df['context'].apply(fun,args=[l]).apply(fun1) + df['response']\n","df1['tweets']= df1['context'].apply(fun,args=[l]).apply(fun1) + df1['response']\n","\n","df['tweets']= df['tweets'].apply(preprocess_text)\n","df1['tweets']=df1['tweets'].apply(preprocess_text)\n","# df['tweets']=df['tweets']+'reply-'+ df['response'].apply(preprocess_text)\n","# df1['tweets']=df1['tweets']+'reply-'+ df1['response'].apply(preprocess_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"362uQOD63xvg","executionInfo":{"status":"ok","timestamp":1626418685612,"user_tz":420,"elapsed":16,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"def935e2-124b-45b0-d505-3ec31c67b596"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>response</th>\n","      <th>context</th>\n","      <th>labels</th>\n","      <th>tweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n","      <td>[A minor child deserves privacy and should be ...</td>\n","      <td>0</td>\n","      <td>@USER I do not get this .. obviously you do ca...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER trying to protest about . Talking ...</td>\n","      <td>[@USER @USER Why is he a loser ? He's just a P...</td>\n","      <td>0</td>\n","      <td>@USER trying to protest about . Talking about ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER @USER He makes an insane about of ...</td>\n","      <td>[Donald J . Trump is guilty as charged . The e...</td>\n","      <td>0</td>\n","      <td>@USER He makes an insane about of money from t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER Meanwhile Trump won't even release...</td>\n","      <td>[Jamie Raskin tanked Doug Collins . Collins lo...</td>\n","      <td>0</td>\n","      <td>@USER Meanwhile Trump will not even release hi...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>SARCASM</td>\n","      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd...</td>\n","      <td>[Man ... y ’ all gone “ both sides ” the apoca...</td>\n","      <td>0</td>\n","      <td>@USER Pretty Sure the Anti-Lincoln Crowd Claim...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     label  ...                                             tweets\n","0  SARCASM  ...  @USER I do not get this .. obviously you do ca...\n","1  SARCASM  ...  @USER trying to protest about . Talking about ...\n","2  SARCASM  ...  @USER He makes an insane about of money from t...\n","3  SARCASM  ...  @USER Meanwhile Trump will not even release hi...\n","4  SARCASM  ...  @USER Pretty Sure the Anti-Lincoln Crowd Claim...\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"676DPU1BOPdp","executionInfo":{"status":"ok","timestamp":1626418685613,"user_tz":420,"elapsed":15,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"0618c07a-2e9f-4894-f507-f9975b27704e"},"source":["# check class distribution\n","df['labels'].value_counts(normalize = True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    0.5\n","0    0.5\n","Name: labels, dtype: float64"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"mjLmL_LFtVjo","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1626418685613,"user_tz":420,"elapsed":10,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"f23ec062-fd51-40f8-fd93-56949c1f68e4"},"source":["df['tweets'][1168]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'@USER There is a huge difference between the words \" no \" and \" know \" .'"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"jdBpFRIL8Fqu","executionInfo":{"status":"ok","timestamp":1626418687224,"user_tz":420,"elapsed":12,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"b4a7ba5c-a8ac-46bc-bebc-287752ed4019"},"source":["df['response'][1168]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'@USER @USER @USER There is a huge difference between the words \" no \" and \" know \" .'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"MKfWnApvOoE7"},"source":["# Split train dataset into train, validation and test sets"]},{"cell_type":"code","metadata":{"id":"mfhSPF5jOWb7"},"source":["\n","X_s = df['tweets'].values\n","y_s = df['labels'].values\n","\n","Xt_s = df1['tweets'].values\n","yt_s = df1['labels'].values\n","\n","train_text, temp_text, train_labels, temp_labels = X_s,Xt_s,y_s,yt_s\n","\n","# we will use temp_text and temp_labels to create validation and test set\n","val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n","                                                                random_state=42, \n","                                                                test_size=0.5, \n","                                                                stratify=temp_labels)\n","val_text, test_text, val_labels, test_labels=temp_text, temp_text, temp_labels, temp_labels\n","\n","# X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.2, random_state=42)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W1jEFb39cCjk"},"source":["# pip install -U sentence-transformers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n7hsdLoCO7uB"},"source":["# Import BERT Model and BERT Tokenizer\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313,"referenced_widgets":["181d7dd797544ef688d6ef848e873976","333a3069022244649f3c035316059996","8fd2e6b9c424495ca46af062b648929d","dee99927ee194dec8dd0487fa0eacb59","36cdbc13d8104dc494626c15d70b17b7","71423e3ba42a4b7595a680f9e8160a15","fd529bfd6a9e493d8b78736c071e0c48","4ba261e6aac24faeb392150a49992e02","7ae82cb237b2419a925e60de3773dc06","a0d89738c20446689d2701b83f7b2518","f93a5c4c3cf34b3e863597e59a572a98","6ed8b93834da4eb8a0d833641611e051","19266f44451544949f2b2849bd218282","020da278d8b04e16929eb633c731f814","88e71ec7da3247e19ce72c66713449bb","f9c570d5fcc64be0b34c1e36978c939f","9d87c16b145d4c03bd3701458e213d93","aae31e9253544a1f9dfd87cfcebad67f","513d872c5dd5408bacd33c174955c10a","b92c23f479a34dd8946710a622dea415","42fcb95f09894cef96bf60d29d1f6e38","488c95ab73f144209ed0a42f32bdd7ad","4fec74fc0aba4261aa3f18c35912a9bb","37c3cb7c989f48e79b0393bb56e13c05","0ef25fafcb784f97ad3a56c4551d508b","1428514a052948e9865b46661db72c9c","4a122bee9d7f4461b6d458500da336c5","f4d8dd72184f43019e08f0cccfa447b1","4a7fe91bce1f40a7ac191af5a2ca24f2","7c55fc79576649b7b2315be211dba7dd","933842e451ac4a0b9b7fd220286fd2b6","fa154cbc310d4b2e90704e55f553e583","31df8c760c704bd78a12c0abcf4e9ae0","320b935363084e97ab74dfaddb2abc39","9acc1b770f4c4f8aa96ce6bd434a0840","e06344f6da984b60a6515f8ae88f09b1","c2d289a32d0445b0bee4a63b8314dfef","793eecdfbd2141d4992197f3ede3ce80","2baa6d6992af4a54a3209040705b47ba","03d61ce22207452da05ef76aa365bc4a"]},"id":"S1kY3gZjO2RE","executionInfo":{"status":"ok","timestamp":1626418738731,"user_tz":420,"elapsed":44148,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"41c1b23e-b4b4-4cee-deac-e9c41ddec491"},"source":["# import BERT-base pretrained model\n","# bert = AutoModel.from_pretrained('bert-base-uncased')\n","\n","# # Load the BERT tokenizer\n","# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","# import BERT-base pretrained model\n","\n","\n","# from transformers import RobertaTokenizer, RobertaModel\n","# bert = RobertaModel.from_pretrained('roberta-base')\n","\n","# # Load the BERT tokenizer\n","# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","\n","\n","from transformers import RobertaTokenizer, RobertaModel\n","bert = RobertaModel.from_pretrained('roberta-large')\n","\n","# Load the BERT tokenizer\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n","\n","# from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","# bert = RobertaForSequenceClassification.from_pretrained('roberta-base')\n","\n","# # Load the BERT tokenizer\n","# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"181d7dd797544ef688d6ef848e873976","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=482.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ae82cb237b2419a925e60de3773dc06","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1425941629.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d87c16b145d4c03bd3701458e213d93","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ef25fafcb784f97ad3a56c4551d508b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31df8c760c704bd78a12c0abcf4e9ae0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_zOKeOMeO-DT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626418739379,"user_tz":420,"elapsed":657,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"e44f559a-7136-4dd4-e1a8-0a544dd6a473"},"source":["# sample data\n","text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n","# encode text\n","sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)\n","\n","# output\n","print(sent_id)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'input_ids': [[0, 9226, 16, 10, 741, 2399, 1421, 35950, 2, 1, 1, 1], [0, 1694, 40, 2051, 12, 90, 4438, 10, 741, 2399, 1421, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8wIYaWI_Prg8"},"source":["# Tokenization"]},{"cell_type":"code","metadata":{"id":"yKwbpeN_PMiu"},"source":["# # get length of all the messages in the train set\n","# seq_len = [len(i.split()) for i in train_text]\n","# for i in train_text:\n","#   print(i)\n","# pd.Series(seq_len).hist(bins = 30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tMA3styN-wXc","executionInfo":{"status":"ok","timestamp":1626418739381,"user_tz":420,"elapsed":14,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"af13a0f0-e25f-4697-c382-a7bfb46be56c"},"source":["total=0\n","for i in range(5000):\n","  total+=len(df['tweets'][i].split())\n","total/5000"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["27.125"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"OXcswEIRPvGe"},"source":["max_seq_len = 100\n","seed=42"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tk5S7DWaP2t6"},"source":["# tokenize and encode sequences in the training set\n","\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = max_seq_len,\n","    padding=True,\n","    truncation=True,    \n",")\n","\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    max_length = max_seq_len,\n","    padding=True,\n","    truncation=True,\n","    return_token_type_ids=False\n","    \n",")\n","\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    max_length = max_seq_len,\n","    padding=True,\n","    truncation=True,\n","    return_token_type_ids=False\n","    \n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aIDkh2QK-2Th","executionInfo":{"status":"ok","timestamp":1626418742716,"user_tz":420,"elapsed":38,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"69765770-fbfb-4b48-d939-878344a2321f"},"source":["count=0\n","maxi=0\n","for i in range(5000):\n","  maxi=max(maxi,len(train_text[i].split()))\n","  if len(train_text[i].split())>76:\n","    count+=1\n","    print(i,df['tweets'][i])\n","    # break\n","# count\n","maxi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3217 @USER Hmmm not too fast face with tears of joy . Marriage to them means / t linking 2 families , sharing in their joys , trials & tribulations . Plus boasting rights .. ah moyo aka inlaw face with tears of joy . New culture , language , distance & reciprocal acceptance was their fear not race per se . But #GenX is global thinking face rolling on the floor laughing rolling on the floor laughing\n","3295 @USER Hmmm not too fast face with tears of joy . Marriage to them means / t linking 2 families , sharing in their joys , trials & tribulations . Plus boasting rights .. ah moyo aka inlaw face with tears of joy . New culture , language , distance & reciprocal acceptance was their fear not race per se . But #GenX is global thinking face rolling on the floor laughing rolling on the floor laughing\n","3925 @USER oncoming fist beating heart folded hands > Our discontent is ours . < backhand index pointing down The Other is Another , not us . People are lenders , not debtors and - - Not ALL - - backhand index pointing down bow , bend and submit themselves ! Some are forged in #Dignity , #Values e #Principles . > What is will never be right . And The is never wrong . < ️ ! \n","4264 That Every People Can Change ! ! And to give Some People A second chance ! ! And the Chance of Redemption ! ! That There Is Good in EveryBody ! ! And That Everyone Can Be ! ! It Teach Us To Believe In Something Good ! ! In People ! ! In Yourself ! ! face blowing a kiss waving hand medium-dark skin tone open hands dark skin tone ‍ ️ ‍ ‍ ️ ‍ \n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["77"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wnQTrAF-2P-","executionInfo":{"status":"ok","timestamp":1626418742716,"user_tz":420,"elapsed":17,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"e6018e7e-d10c-4f6d-976c-1a08a5376581"},"source":["print(train_text[3217])\n","print(tokens_train.data['input_ids'][3217])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["@USER Hmmm not too fast face with tears of joy . Marriage to them means / t linking 2 families , sharing in their joys , trials & tribulations . Plus boasting rights .. ah moyo aka inlaw face with tears of joy . New culture , language , distance & reciprocal acceptance was their fear not race per se . But #GenX is global thinking face rolling on the floor laughing rolling on the floor laughing\n","[0, 1039, 47955, 289, 41311, 45, 350, 1769, 652, 19, 6941, 9, 5823, 479, 29795, 7, 106, 839, 1589, 326, 14135, 132, 1232, 2156, 3565, 11, 49, 5823, 29, 2156, 7341, 359, 28406, 16685, 479, 4642, 24764, 659, 29942, 23184, 475, 2160, 139, 19056, 11, 4656, 652, 19, 6941, 9, 5823, 479, 188, 2040, 2156, 2777, 2156, 4472, 359, 36285, 10502, 21, 49, 2490, 45, 1015, 228, 842, 479, 125, 849, 15887, 1000, 16, 720, 2053, 652, 6346, 15, 5, 1929, 11339, 6346, 15, 5, 1929, 11339, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nl7Q3K1q-2Oc","executionInfo":{"status":"ok","timestamp":1626418742717,"user_tz":420,"elapsed":11,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"c5facb0a-7a1f-43e6-c419-fde4ef07ddff"},"source":["print(tokenizer.get_vocab()[\"her\"])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1843\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wsm8bkRZQTw9"},"source":["# Convert Integer Sequences to Tensors"]},{"cell_type":"code","metadata":{"id":"QR-lXwmzQPd6"},"source":["# for train set\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","# for validation set\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","# for test set\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ov1cOBlcRLuk"},"source":["# Create DataLoaders"]},{"cell_type":"code","metadata":{"id":"qUy9JKFYQYLp"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","#define a batch size\n","batch_size = 32\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K2HZc5ZYRV28"},"source":["# Freeze BERT Parameters"]},{"cell_type":"code","metadata":{"id":"wHZ0MC00RQA_"},"source":["# freeze all the parameters\n","for param in bert.parameters():\n","    param.requires_grad = True\n","# print(bert)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s7ahGBUWRi3X"},"source":["# Define Model Architecture"]},{"cell_type":"code","metadata":{"id":"b3iEtGyYRd0A"},"source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, bert):\n","      \n","      super(BERT_Arch, self).__init__()\n","\n","      self.bert = bert \n","      \n","      # dropout layer\n","      self.dropout = nn.Dropout(0.1)\n","      \n","      # relu activation function\n","      self.relu =  nn.ReLU()\n","\n","      # dense layer 1\n","      self.fc1 = nn.Linear(1024,256)\n","      \n","      # dense layer 2 (Output layer)\n","      self.fc2 = nn.Linear(256,2)\n","\n","      #softmax activation function\n","      self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","\n","      #pass the inputs to the model  \n","      _,cls_hs = self.bert(sent_id,mask, return_dict=False)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn11111 \",cls_hs.shape)\n","      x = self.fc1(cls_hs)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      x = self.relu(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      x = self.dropout(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      # output layer\n","      x = self.fc2(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      # apply softmax activation\n","      x = self.softmax(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkzQrcKaj74E"},"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(bert)\n","\n","# push the model to GPU\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"taXS0IilRn9J"},"source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = AdamW(model.parameters(), lr = 2e-5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j9CDpoMQR_rK"},"source":["# Find Class Weights"]},{"cell_type":"code","metadata":{"id":"izY5xH5eR7Ur"},"source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","#compute the class weights\n","class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n","\n","print(class_wts)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r1WvfY2vSGKi"},"source":["# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","cross_entropy  = nn.NLLLoss(weight=weights) \n","\n","# number of training epochs\n","epochs = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"My4CA0qaShLq"},"source":["# Fine-Tune BERT"]},{"cell_type":"code","metadata":{"id":"rskLk8R_SahS"},"source":["# function to train the model\n","def train():\n","  \n","  model.train()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save model predictions\n","  total_preds=[]\n","  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):\n","    \n","    # progress update after every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n"," \n","    sent_id, mask, labels = batch\n","\n","    # clear previously calculated gradients \n","    model.zero_grad()        \n","\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask)\n","\n","    # compute the loss between actual and predicted values\n","    loss = cross_entropy(preds, labels)\n","\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    # update parameters\n","    xm.optimizer_step(optimizer)\n","    # optimizer.step()\n","\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)\n","  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yGXovFDlSxB5"},"source":["# function for evaluating the model\n","def evaluate():\n","  \n","  print(\"\\nEvaluating...\")\n","  \n","  # deactivate dropout layers\n","  model.eval()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save the model predictions\n","  total_preds = []\n","\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):\n","    \n","    # Progress update every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      \n","      # Calculate elapsed time in minutes.\n","      # elapsed = format_time(time.time() - t0)\n","            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","\n","    sent_id, mask, labels = batch\n","\n","    # deactivate autograd\n","    with torch.no_grad():\n","      \n","      # model predictions\n","      preds = model(sent_id, mask)\n","\n","      # compute the validation loss between actual and predicted values\n","      loss = cross_entropy(preds,labels)\n","\n","      total_loss = total_loss + loss.item()\n","\n","      preds = preds.detach().cpu().numpy()\n","\n","      total_preds.append(preds)\n","\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WHQlio6yM_QH"},"source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","# !nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9KZEgxRRTLXG"},"source":["# Start Model Training"]},{"cell_type":"code","metadata":{"id":"k1USGTntS3TS"},"source":["# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","#for each epoch\n","epochs=1\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss,_ = train()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'saved_weights.pt')\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","\n","    # get predictions for test data\n","    # !nvidia-smi\n","    # with torch.no_grad():\n","    #   preds = model(test_seq.to(device), test_mask.to(device))\n","    #   preds = preds.detach().cpu().numpy()\n","    # preds = np.argmax(preds, axis = 1)\n","    # print(classification_report(test_y, preds))\n","    # print(accuracy_score(test_y, preds))\n","\n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_yrhUc9kTI5a"},"source":["# Load Saved Model"]},{"cell_type":"code","metadata":{"id":"OacxUyizS8d1"},"source":["#load weights of best model\n","path = 'saved_weights.pt'\n","model.load_state_dict(torch.load(path))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x4SVftkkTZXA"},"source":["# Get Predictions for Test Data"]},{"cell_type":"code","metadata":{"id":"NZl0SZmFTRQA"},"source":["pred=[]\n","with torch.no_grad():\n","  for i in range(0,90):\n","    preds = model(test_seq[i*20:i*20+20].to(device), test_mask[i*20:i*20+20].to(device))\n","    preds = preds.detach().cpu().numpy()\n","    pred.append(preds)\n","print(np.array(pred).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfHQYSOAgLyT"},"source":["pred1=np.array(pred)\n","# pred1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fmSzWK63gL5z"},"source":["pred2=pred1.reshape((1800,2))\n","pred2.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQ_1m2WhgL7k"},"source":["p=pd.DataFrame(pred2)\n","p.to_csv('Rresponse.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d8su6xM8gSNJ"},"source":["pred3 = np.argmax(pred2, axis = 1)\n","pred3 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZMw2NRnngSQs"},"source":["print(classification_report(test_y, pred3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5K4dl1AQgShx"},"source":["# confusion matrix\n","# print(pred)\n","pd.crosstab(test_y, pred3)\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","print(accuracy_score(test_y, pred3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W14537b4ubb6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G0psIEgeubdz","colab":{"base_uri":"https://localhost:8080/","height":420},"executionInfo":{"status":"ok","timestamp":1626419627434,"user_tz":420,"elapsed":379,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"ee926fd7-ac46-4d0c-ead0-4f8e182867b3"},"source":["brcc=pd.read_csv('/content/drive/MyDrive/sarcasm-detection/Results/bert/73.77_response_only.csv')\n","brcc"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>-0.752169</td>\n","      <td>-0.637415</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>-0.193796</td>\n","      <td>-1.736283</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>-0.170170</td>\n","      <td>-1.854833</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>-0.569712</td>\n","      <td>-0.833993</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>-0.060625</td>\n","      <td>-2.833202</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1795</th>\n","      <td>1795</td>\n","      <td>-1.910129</td>\n","      <td>-0.160241</td>\n","    </tr>\n","    <tr>\n","      <th>1796</th>\n","      <td>1796</td>\n","      <td>-2.255020</td>\n","      <td>-0.110788</td>\n","    </tr>\n","    <tr>\n","      <th>1797</th>\n","      <td>1797</td>\n","      <td>-0.371105</td>\n","      <td>-1.171092</td>\n","    </tr>\n","    <tr>\n","      <th>1798</th>\n","      <td>1798</td>\n","      <td>-3.717061</td>\n","      <td>-0.024606</td>\n","    </tr>\n","    <tr>\n","      <th>1799</th>\n","      <td>1799</td>\n","      <td>-3.675460</td>\n","      <td>-0.025664</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1800 rows × 3 columns</p>\n","</div>"],"text/plain":["      Unnamed: 0         0         1\n","0              0 -0.752169 -0.637415\n","1              1 -0.193796 -1.736283\n","2              2 -0.170170 -1.854833\n","3              3 -0.569712 -0.833993\n","4              4 -0.060625 -2.833202\n","...          ...       ...       ...\n","1795        1795 -1.910129 -0.160241\n","1796        1796 -2.255020 -0.110788\n","1797        1797 -0.371105 -1.171092\n","1798        1798 -3.717061 -0.024606\n","1799        1799 -3.675460 -0.025664\n","\n","[1800 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"id":"1eyDGkYuubhK"},"source":["# brc=pd.read_csv('context_1+r_2e.csv')\n","# brc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ms1ObHZxTYSI"},"source":["# br=pd.read_csv('response1.csv')\n","# br"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YqzLS7rHTp4T"},"source":["# bc=pd.read_csv('contexto.csv')\n","# bc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jpX1uTwjUPY6"},"source":["# bertc=np.array(bc[['0','1']])\n","# bertc1=np.multiply(bertc,0.1)\n","\n","bertrcc=np.array(brcc[['0','1']])\n","bertrcc1=np.multiply(bertrcc,1)\n","\n","# bertcr=np.array(brc[['0','1']])\n","# bertcr1=np.multiply(bertcr,0.4)\n","\n","# bertr=np.array(br[['0','1']])\n","# bertr1=np.multiply(bertr,0.4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BY2P7H1W2Wo4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626419627827,"user_tz":420,"elapsed":7,"user":{"displayName":"Abhishek Ranjan.","photoUrl":"","userId":"10050815449966213198"}},"outputId":"9d6078f2-e925-4665-cfab-93ee1b543bac"},"source":["# yhats = [bertc1,bertr1,bertcr1,bertrcc1]\n","yhats = [bertrcc1]\n","# import numpy as np\n","yhats = np.array(yhats)\n","\n","# # sum across ensemble members\n","summed = np.sum(yhats, axis=0)\n","# # argmax across classes\n","result = np.argmax(summed, axis=1)\n","# result = np.argmax(yhats, axis=0)\n","print(result)\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","accuracy_score(result,test_y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1 0 0 ... 0 1 1]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.7377777777777778"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"code","metadata":{"id":"7l50ByhFHRB0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xo3EINCmHSHv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yQfTjqgHHSEM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mfteR1ckHSB5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AAfMEeHGHSAc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"giGYLahZHR-y"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JDHy31lEHR6q"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9kRzWbQUHR32"},"source":[""],"execution_count":null,"outputs":[]}]}