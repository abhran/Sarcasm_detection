{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Fine-Tuning BERT+NetVlad+NextVlad....ipynb","provenance":[{"file_id":"1FdZjlf-71sxhRiAzpixL6KhFr69JBLyW","timestamp":1621160720798},{"file_id":"1ftGKQ22ZBSIX_d6KEpUI7vRczYgtQPMF","timestamp":1620983839237},{"file_id":"https://github.com/prateekjoshi565/Fine-Tuning-BERT/blob/master/Fine_Tuning_BERT_for_Spam_Classification.ipynb","timestamp":1619947106006}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OFOTiqrtNvyy"},"source":["# Install Transformers Library"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hkhc10wNrGt","executionInfo":{"status":"ok","timestamp":1623870787438,"user_tz":420,"elapsed":2962,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"b1cf9f19-e303-45e4-f962-30a6ddef86f5"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4giRzM7NtHJ"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast\n","\n","# specify GPU\n","device = torch.device(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7sYuExU3YiR4","executionInfo":{"status":"ok","timestamp":1623870789612,"user_tz":420,"elapsed":44,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"738c5545-1e54-47fb-c5ba-32b35ffd9f08"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kKd-Tj3hOMsZ"},"source":["# Load Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"cwJrQFQgN_BE","executionInfo":{"status":"ok","timestamp":1623870789614,"user_tz":420,"elapsed":34,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"044f71ba-0d4b-4e6e-935c-fd632e1e7a27"},"source":["\n","df = pd.read_json('/content/drive/MyDrive/sarcasm-detection/Datasets/twitter/sarcasm_detection_shared_task_twitter_training.jsonl',lines=True)\n","df1 = pd.read_json('/content/drive/MyDrive/sarcasm-detection/Datasets/twitter/sarcasm_detection_shared_task_twitter_testing.jsonl',lines=True)\n","\n","df['labels'] = df['label'].apply(lambda x: ['SARCASM', 'NOT_SARCASM'].index(x))\n","df1['labels'] = df1['label'].apply(lambda x: ['SARCASM', 'NOT_SARCASM'].index(x))\n","df1.tail()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>context</th>\n","      <th>response</th>\n","      <th>id</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1795</th>\n","      <td>NOT_SARCASM</td>\n","      <td>[I have been a business customer of MWeb @USER...</td>\n","      <td>@USER @USER @USER is definitely the best out t...</td>\n","      <td>twitter_1796</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1796</th>\n","      <td>SARCASM</td>\n","      <td>[A woman refuses to have her temperature taken...</td>\n","      <td>@USER @USER Ye let her out run wild and infect...</td>\n","      <td>twitter_1797</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1797</th>\n","      <td>SARCASM</td>\n","      <td>[The reason big government wants @USER out is ...</td>\n","      <td>@USER @USER @USER Thanks for that , I would ha...</td>\n","      <td>twitter_1798</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1798</th>\n","      <td>NOT_SARCASM</td>\n","      <td>[Happy #musicmonday and #thanks for #all your ...</td>\n","      <td>@USER @USER @USER Yes also #found this on #new...</td>\n","      <td>twitter_1799</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1799</th>\n","      <td>NOT_SARCASM</td>\n","      <td>[Not long wrapped on the amazing #January22nd ...</td>\n","      <td>@USER @USER @USER you still need to send the l...</td>\n","      <td>twitter_1800</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            label  ... labels\n","1795  NOT_SARCASM  ...      1\n","1796      SARCASM  ...      0\n","1797      SARCASM  ...      0\n","1798  NOT_SARCASM  ...      1\n","1799  NOT_SARCASM  ...      1\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"U7WBye79ZKoO"},"source":["df[\"tweets\"]=df['response']\n","df1[\"tweets\"]=df1['response']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fzPPOrVQWiW5","executionInfo":{"status":"ok","timestamp":1623870789615,"user_tz":420,"elapsed":28,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"e9645292-384d-4af7-f763-28057e5c1e0b"},"source":["df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5000, 5)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"676DPU1BOPdp","executionInfo":{"status":"ok","timestamp":1623870789616,"user_tz":420,"elapsed":20,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"fc674249-eecf-470c-beb2-d0f8183e83cc"},"source":["# check class distribution\n","df['labels'].value_counts(normalize = True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    0.5\n","0    0.5\n","Name: labels, dtype: float64"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"MKfWnApvOoE7"},"source":["# Split train dataset into train, validation and test sets"]},{"cell_type":"code","metadata":{"id":"mfhSPF5jOWb7"},"source":["\n","X_s = df['tweets'].values\n","y_s = df['labels'].values\n","\n","Xt_s = df1['tweets'].head(1000).values\n","yt_s = df1['labels'].head(1000).values\n","\n","train_text, temp_text, train_labels, temp_labels = X_s,Xt_s,y_s,yt_s\n","\n","# we will use temp_text and temp_labels to create validation and test set\n","# val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n","#                                                                 random_state=2018, \n","#                                                                 test_size=0.5, \n","#                                                                 stratify=temp_labels)\n","val_text, test_text, val_labels, test_labels=temp_text, temp_text, temp_labels, temp_labels\n","\n","# X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.2, random_state=42)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W1jEFb39cCjk"},"source":["# pip install -U sentence-transformers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n7hsdLoCO7uB"},"source":["# Import BERT Model and BERT Tokenizer\n","\n","https://huggingface.co/transformers/pretrained_models.html"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S1kY3gZjO2RE","executionInfo":{"status":"ok","timestamp":1623870796768,"user_tz":420,"elapsed":7165,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"dd0c344b-1bd8-4bfa-8a63-51efc711b126"},"source":["# import BERT-base pretrained model\n","# bert = AutoModel.from_pretrained('bert-base-uncased')\n","\n","# # Load the BERT tokenizer\n","# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","bert = AutoModel.from_pretrained('bert-large-cased')\n","\n","# Load the BERT tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained('bert-large-cased')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_zOKeOMeO-DT"},"source":["# sample data\n","text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n","# encode text\n","sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oAH73n39PHLw","executionInfo":{"status":"ok","timestamp":1623870796770,"user_tz":420,"elapsed":41,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"5f02ae5f-9c15-4ae0-e091-64d652f901ff"},"source":["# output\n","print(sent_id)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'input_ids': [[101, 1142, 1110, 170, 1129, 3740, 2235, 17463, 2916, 102, 0], [101, 1195, 1209, 2503, 118, 9253, 170, 1129, 3740, 2235, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8wIYaWI_Prg8"},"source":["# Tokenization"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"yKwbpeN_PMiu","executionInfo":{"status":"ok","timestamp":1623870797767,"user_tz":420,"elapsed":1034,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"32bb294d-b398-4dcf-9a34-3f20e0825464"},"source":["# get length of all the messages in the train set\n","seq_len = [len(i.split()) for i in train_text]\n","\n","pd.Series(seq_len).hist(bins = 30)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f7cab95bd90>"]},"metadata":{"tags":[]},"execution_count":13},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"OXcswEIRPvGe"},"source":["max_seq_len = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tk5S7DWaP2t6","executionInfo":{"status":"ok","timestamp":1623870797769,"user_tz":420,"elapsed":21,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"b60cdd8f-8ba6-463a-f6b5-4adb379aeb99"},"source":["# tokenize and encode sequences in the training set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Wsm8bkRZQTw9"},"source":["# Convert Integer Sequences to Tensors"]},{"cell_type":"code","metadata":{"id":"QR-lXwmzQPd6"},"source":["# for train set\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","# for validation set\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","# for test set\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ov1cOBlcRLuk"},"source":["# Create DataLoaders"]},{"cell_type":"code","metadata":{"id":"qUy9JKFYQYLp"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","#define a batch size\n","batch_size = 32\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K2HZc5ZYRV28"},"source":["# Freeze BERT Parameters"]},{"cell_type":"code","metadata":{"id":"wHZ0MC00RQA_"},"source":["# freeze all the parameters\n","for param in bert.parameters():\n","    param.requires_grad = True\n","# print(bert)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7s27YkBMtvWz"},"source":["#Define Model Layers"]},{"cell_type":"code","metadata":{"id":"PDtctFjltkQG"},"source":["class BiRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes,dropout):\n","        super(BiRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,dropout=dropout, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n","    \n","    def forward(self, x):\n","        # Set initial states\n","        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n","        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n","        \n","        # Forward propagate LSTM\n","        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n","        \n","        # Decode the hidden state of the last time step\n","        out = self.fc(out[:, -1, :])\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"buwGWYZQtt52"},"source":["  \n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class NetVLAD(nn.Module):\n","    \"\"\"NetVLAD layer implementation\"\"\"\n","\n","    def __init__(self, num_clusters=64, dim=128, alpha=100.0,\n","                 normalize_input=True):\n","        \"\"\"\n","        Args:\n","            num_clusters : int\n","                The number of clusters\n","            dim : int\n","                Dimension of descriptors\n","            alpha : float\n","                Parameter of initialization. Larger value is harder assignment.\n","            normalize_input : bool\n","                If true, descriptor-wise L2 normalization is applied to input.\n","        \"\"\"\n","        super(NetVLAD, self).__init__()\n","        self.num_clusters = num_clusters\n","        self.dim = dim\n","        self.alpha = alpha\n","        self.normalize_input = normalize_input\n","        self.conv = nn.Conv2d(dim, num_clusters, kernel_size=(1, 1), bias=True)\n","        self.centroids = nn.Parameter(torch.rand(num_clusters, dim))\n","        self._init_params()\n","\n","    def _init_params(self):\n","        self.conv.weight = nn.Parameter(\n","            (2.0 * self.alpha * self.centroids).unsqueeze(-1).unsqueeze(-1)\n","        )\n","        self.conv.bias = nn.Parameter(\n","            - self.alpha * self.centroids.norm(dim=1)\n","        )\n","\n","    def forward(self, x):\n","        N, C = x.shape[:2]\n","\n","        if self.normalize_input:\n","            x = F.normalize(x, p=2, dim=1)  # across descriptor dim\n","\n","        # soft-assignment\n","        soft_assign = self.conv(x).view(N, self.num_clusters, -1)\n","        soft_assign = F.softmax(soft_assign, dim=1)\n","\n","        x_flatten = x.view(N, C, -1)\n","        \n","        # calculate residuals to each clusters\n","        residual = x_flatten.expand(self.num_clusters, -1, -1, -1).permute(1, 0, 2, 3) - \\\n","            self.centroids.expand(x_flatten.size(-1), -1, -1).permute(1, 2, 0).unsqueeze(0)\n","        residual *= soft_assign.unsqueeze(2)\n","        vlad = residual.sum(dim=-1)\n","\n","        vlad = F.normalize(vlad, p=2, dim=2)  # intra-normalization\n","        vlad = vlad.view(x.size(0), -1)  # flatten\n","        vlad = F.normalize(vlad, p=2, dim=1)  # L2 normalize\n","\n","        return vlad"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6L8diAaXzBEt"},"source":["class NeXtVLAD(object):\n","    \"\"\"\n","  This is a paddlepaddle implementation of the NeXtVLAD model. For more\n","  information, please refer to the paper,\n","   https://static.googleusercontent.com/media/research.google.com/zh-CN//youtube8m/workshop2018/p_c03.pdf\n","  \"\"\"\n","\n","    def __init__(self,\n","                 feature_size,\n","                 cluster_size,\n","                 is_training=True,\n","                 expansion=2,\n","                 groups=None,\n","                 inputname='video'):\n","        self.feature_size = feature_size\n","        self.cluster_size = cluster_size\n","        self.is_training = is_training\n","        self.expansion = expansion\n","        self.groups = groups\n","        self.name = inputname + '_'\n","\n","    def forward(self, input):\n","        input = fluid.layers.fc(\n","            input=input,\n","            size=self.expansion * self.feature_size,\n","            act=None,\n","            name=self.name + 'fc_expansion',\n","            param_attr=fluid.ParamAttr(\n","                name=self.name + 'fc_expansion_w',\n","                initializer=fluid.initializer.MSRA(uniform=False)),\n","            bias_attr=fluid.ParamAttr(\n","                name=self.name + 'fc_expansion_b',\n","                initializer=fluid.initializer.Constant(value=0.)))\n","\n","        # attention factor of per group\n","        attention = fluid.layers.fc(\n","            input=input,\n","            size=self.groups,\n","            act='sigmoid',\n","            name=self.name + 'fc_group_attention',\n","            param_attr=fluid.ParamAttr(\n","                name=self.name + 'fc_group_attention_w',\n","                initializer=fluid.initializer.MSRA(uniform=False)),\n","            bias_attr=fluid.ParamAttr(\n","                name=self.name + 'fc_group_attention_b',\n","                initializer=fluid.initializer.Constant(value=0.)))\n","\n","        # calculate activation factor of per group per cluster\n","        feature_size = self.feature_size * self.expansion // self.groups\n","        cluster_weights = fluid.layers.create_parameter(\n","            shape=[\n","                self.expansion * self.feature_size,\n","                self.groups * self.cluster_size\n","            ],\n","            dtype=input.dtype,\n","            attr=fluid.ParamAttr(name=self.name + 'cluster_weights'),\n","            default_initializer=fluid.initializer.MSRA(uniform=False))\n","\n","        activation = fluid.layers.matmul(input, cluster_weights)\n","        activation = fluid.layers.batch_norm(\n","            activation, is_test=(not self.is_training))\n","\n","        # reshape of activation\n","        activation = fluid.layers.reshape(activation,\n","                                          [-1, self.groups, self.cluster_size])\n","        # softmax on per cluster\n","        activation = fluid.layers.softmax(activation)\n","        activation = fluid.layers.elementwise_mul(activation, attention, axis=0)\n","        a_sum = fluid.layers.sequence_pool(activation, 'sum')\n","        a_sum = fluid.layers.reduce_sum(a_sum, dim=1)\n","\n","        # create cluster_weights2\n","        cluster_weights2 = fluid.layers.create_parameter(\n","            shape=[self.cluster_size, feature_size],\n","            dtype=input.dtype,\n","            attr=fluid.ParamAttr(name=self.name + 'cluster_weights2'),\n","            default_initializer=fluid.initializer.MSRA(uniform=False))\n","\n","        # expand a_sum dimension from [-1, self.cluster_size] to be [-1, self.cluster_size, feature_size]\n","        a_sum = fluid.layers.reshape(a_sum, [-1, self.cluster_size, 1])\n","        a_sum = fluid.layers.expand(a_sum, [1, 1, feature_size])\n","\n","        # element wise multiply a_sum and cluster_weights2\n","        a = fluid.layers.elementwise_mul(\n","            a_sum, cluster_weights2,\n","            axis=1)  # output shape [-1, self.cluster_size, feature_size]\n","\n","        # transpose activation from [-1, self.groups, self.cluster_size] to [-1, self.cluster_size, self.groups]\n","        activation2 = fluid.layers.transpose(activation, perm=[0, 2, 1])\n","        # transpose op will clear the lod infomation, so it should be reset\n","        activation = fluid.layers.lod_reset(activation2, activation)\n","\n","        # reshape input from [-1, self.expansion * self.feature_size] to [-1, self.groups, feature_size]\n","        reshaped_input = fluid.layers.reshape(input,\n","                                              [-1, self.groups, feature_size])\n","        # mat multiply activation and reshaped_input\n","        vlad = fluid.layers.matmul(\n","            activation,\n","            reshaped_input)  # output shape [-1, self.cluster_size, feature_size]\n","        vlad = fluid.layers.sequence_pool(vlad, 'sum')\n","        vlad = fluid.layers.elementwise_sub(vlad, a)\n","\n","        # l2_normalization\n","        vlad = fluid.layers.transpose(vlad, [0, 2, 1])\n","        vlad = fluid.layers.l2_normalize(vlad, axis=1)\n","\n","        # reshape and batch norm\n","        vlad = fluid.layers.reshape(vlad,\n","                                    [-1, self.cluster_size * feature_size])\n","        vlad = fluid.layers.batch_norm(vlad, is_test=(not self.is_training))\n","\n","        return vlad"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s7ahGBUWRi3X"},"source":["# Define Model Architecture"]},{"cell_type":"code","metadata":{"id":"b3iEtGyYRd0A"},"source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, bert):\n","      \n","      super(BERT_Arch, self).__init__()\n","\n","      self.bert = bert \n","      \n","      # dropout layer\n","      # self.dropout = nn.Dropout(0.1)\n","      \n","      # relu activation function\n","      # self.relu =  nn.ReLU()\n","\n","      # dense layer 1\n","      # self.fc1 = nn.Linear(768,512)\n","      # self.fc1 = BiRNN(input_size=32768, hidden_size=1024, num_layers=2,num_classes=512,dropout=0.25).to(device) \n","\n","      # self.fc1 = nn.LSTM(input_size=768, hidden_size=1024, num_layers=2, batch_first=True,dropout=0.25, bidirectional=True).to(device)\n","      self.fc1 = BiRNN(input_size=1024, hidden_size=1024, num_layers=2,num_classes=512,dropout=0.25).to(device)\n","      # self.fc1_2 = NetVLAD(dim=512,num_clusters= 32, normalize_input=False).to(device)   \n","      \n","      \n","      \n","      \n","      # dense layer 2 (Output layer)\n","      self.fc2 = nn.Linear(512,64)\n","      self.fc2_3 = nn.Linear(64,2)\n","\n","\n","\n","\n","\n","      #softmax activation function\n","      self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","\n","      #pass the inputs to the model  \n","      _, cls_hs = self.bert(sent_id,mask, return_dict=False)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn \",cls_hs.shape)\n","      # !nvidia-smi\n","      \n","      # x = self.fc1(cls_hs)\n","\n","      # x = self.relu(x)\n","\n","      # x = self.dropout(x)\n","      x = cls_hs.view(-1,1,1024)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuex \",x.shape)\n","\n","      x = self.fc1(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuex \",x.shape)\n","      \n","\n","      # x = x.view(-1,512,1,1)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn \",x.shape)\n","\n","      # x = self.fc1_2(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn \",x.shape)\n","      \n","      # output layer\n","      x = self.fc2(x)\n","      x=self.fc2_3(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn \",x.shape)\n","      \n","      # apply softmax activation\n","      x = self.softmax(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn \",x.shape)\n","\n","      return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cBAJJVuJRliv"},"source":["# pass the pre-trained BERT to our define architecture\n","import torch\n","torch.cuda.empty_cache()\n","import gc\n","# del variables\n","gc.collect()\n","model = BERT_Arch(bert)\n","\n","# push the model to GPU\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hNCYTtSu_e1Q"},"source":["#Define Cyclic Learning Rate"]},{"cell_type":"code","metadata":{"id":"taXS0IilRn9J"},"source":["# optimizer from hugging face transformers\n","import math\n","\n","# # number of training epochs\n","epochs = 10\n","\n","\n","from transformers import AdamW\n","\n","# define the optimizer\n","# optimizer = torch.optim.SGD(model.parameters(), lr=2e-4)\n","optimizer = AdamW(model.parameters(), lr = 2e-6)\n","\n","# scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma=.999,last_epoch = 1,verbose = True)\t\n","# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-5, max_lr=2e-4, step_size_up=200, step_size_down=None, mode='triangular', gamma=1.0, scale_fn=None, scale_mode='cycle', cycle_momentum=True, base_momentum=0.725, max_momentum=0.825, last_epoch=-1, verbose=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j9CDpoMQR_rK"},"source":["# Find Class Weights"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"izY5xH5eR7Ur","executionInfo":{"status":"ok","timestamp":1623870802509,"user_tz":420,"elapsed":41,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"366bdd57-4f56-4bde-e5d8-a9e3375c7df3"},"source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","#compute the class weights\n","class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n","\n","print(class_wts)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1. 1.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r1WvfY2vSGKi"},"source":["# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","cross_entropy  = nn.NLLLoss(weight=weights) \n","\n","# number of training epochs\n","# epochs = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"My4CA0qaShLq"},"source":["# Fine-Tune BERT"]},{"cell_type":"code","metadata":{"id":"rskLk8R_SahS"},"source":["# function to train the model\n","def train():\n","  \n","  model.train()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save model predictions\n","  total_preds=[]\n","  # Make lists to capture the logs\n","\n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):\n","    \n","    # progress update after every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n"," \n","    sent_id, mask, labels = batch\n","\n","    # clear previously calculated gradients \n","    model.zero_grad()        \n","\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask)\n","\n","    # compute the loss between actual and predicted values\n","    loss = cross_entropy(preds, labels)\n","\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    # update parameters\n","    optimizer.step()\n","\n","    # Update LR\n","    # scheduler.step()\n","\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)\n","  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yGXovFDlSxB5"},"source":["# function for evaluating the model\n","def evaluate():\n","  \n","  print(\"\\nEvaluating...\")\n","  \n","  # deactivate dropout layers\n","  model.eval()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save the model predictions\n","  total_preds = []\n","\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):\n","    \n","    # Progress update every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      \n","      # Calculate elapsed time in minutes.\n","      # elapsed = format_time(time.time() - t0)\n","            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","\n","    sent_id, mask, labels = batch\n","\n","    # deactivate autograd\n","    with torch.no_grad():\n","      \n","      # model predictions\n","      preds = model(sent_id, mask)\n","\n","      # compute the validation loss between actual and predicted values\n","      loss = cross_entropy(preds,labels)\n","\n","      total_loss = total_loss + loss.item()\n","\n","      preds = preds.detach().cpu().numpy()\n","\n","      total_preds.append(preds)\n","\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtLeWZgtJ23W","executionInfo":{"status":"ok","timestamp":1623870802511,"user_tz":420,"elapsed":35,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"4ebafe1b-cb31-4d8f-96dd-5a50142a6489"},"source":["import torch\n","torch.cuda.empty_cache()\n","import gc\n","from torch.autograd import Variable\n","del Variable\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["200"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"9KZEgxRRTLXG"},"source":["# Start Model Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k1USGTntS3TS","executionInfo":{"status":"ok","timestamp":1623873689525,"user_tz":420,"elapsed":310430,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"9a088694-c0b3-4e1f-beb0-a91d254a5605"},"source":["import torch\n","torch.cuda.empty_cache()\n","import gc\n","# del variables\n","gc.collect()\n","\n","\n","# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","#for each epoch\n","epochs=1\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss,_ = train()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'saved_weights.pt')\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","\n","\n","    import torch\n","    torch.cuda.empty_cache()\n","    import gc\n","    # del variables\n","    gc.collect()\n","    !nvidia-smi\n","\n","    # with torch.no_grad():\n","    #   preds = model(test_seq.to(device), test_mask.to(device))\n","    #   preds = preds.detach().cpu().numpy()\n","    # # model's performance\n","    # preds = np.argmax(preds, axis = 1)\n","    # print(classification_report(test_y, preds))\n","    \n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," Epoch 1 / 1\n","  Batch    50  of    157.\n","  Batch   100  of    157.\n","  Batch   150  of    157.\n","\n","Evaluating...\n","Wed Jun 16 20:01:29 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   74C    P0    37W /  70W |   7386MiB / 15109MiB |     21%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n","\n","Training Loss: 0.383\n","Validation Loss: 0.626\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tFbVyimeN7aJ","executionInfo":{"status":"ok","timestamp":1623873689527,"user_tz":420,"elapsed":42,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"9a6945a9-03ce-4b48-a200-1eb7db22756a"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Wed Jun 16 20:01:30 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   74C    P0    37W /  70W |   7386MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_yrhUc9kTI5a"},"source":["# Load Saved Model"]},{"cell_type":"code","metadata":{"id":"OacxUyizS8d1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623873690712,"user_tz":420,"elapsed":1215,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"4dacc58a-cf33-4730-df45-b82631fa2928"},"source":["#load weights of best model\n","path = 'saved_weights.pt'\n","model.load_state_dict(torch.load(path))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uutqqNjQN47N","executionInfo":{"status":"ok","timestamp":1623873690713,"user_tz":420,"elapsed":26,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"bb1eb442-a7d4-4c3f-bbd6-1cb17e9ddfb8"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Wed Jun 16 20:01:31 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P0    42W /  70W |   8524MiB / 15109MiB |     19%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x4SVftkkTZXA"},"source":["# Get Predictions for Test Data"]},{"cell_type":"code","metadata":{"id":"NZl0SZmFTRQA"},"source":["# get predictions for test data\n","import torch\n","torch.cuda.empty_cache()\n","import gc\n","from torch.autograd import Variable\n","del Variable\n","gc.collect()\n","\n","with torch.no_grad():\n","  preds = model(test_seq.to(device), test_mask.to(device))\n","  preds = preds.detach().cpu().numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ms1ObHZxTYSI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623873710426,"user_tz":420,"elapsed":57,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"ae4faf0e-749a-4f2a-b1de-794972d3083b"},"source":["# model's performance\n","preds = np.argmax(preds, axis = 1)\n","print(classification_report(test_y, preds))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.69      0.74      0.71       491\n","           1       0.73      0.68      0.71       509\n","\n","    accuracy                           0.71      1000\n","   macro avg       0.71      0.71      0.71      1000\n","weighted avg       0.71      0.71      0.71      1000\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RcXXnXR7N0KP","executionInfo":{"status":"ok","timestamp":1623873710427,"user_tz":420,"elapsed":49,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"e216bdaa-7719-4c17-b589-2855c4ad7f74"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Wed Jun 16 20:01:50 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   78C    P0    40W /  70W |  14094MiB / 15109MiB |     99%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YqzLS7rHTp4T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623873710428,"user_tz":420,"elapsed":43,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"faac2cb7-8205-4ab7-abdd-74f4c73b1028"},"source":["# confusion matrix\n","# pd.crosstab(test_y, preds)\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","print(accuracy_score(test_y, preds))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.71\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QJttpRCVN2B5","executionInfo":{"status":"ok","timestamp":1623873710429,"user_tz":420,"elapsed":38,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"5e7ab998-06a2-4193-c03d-dd6027e3a152"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Wed Jun 16 20:01:51 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   78C    P0    43W /  70W |  14094MiB / 15109MiB |     10%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jpX1uTwjUPY6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623873711195,"user_tz":420,"elapsed":27,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"866d0df0-4f6f-4f03-fd11-01bfe4f8fada"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Wed Jun 16 20:01:51 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   78C    P0    43W /  70W |  14094MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BY2P7H1W2Wo4"},"source":[""],"execution_count":null,"outputs":[]}]}