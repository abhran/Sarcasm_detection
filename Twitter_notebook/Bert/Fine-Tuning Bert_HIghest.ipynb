{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fine-Tuning Bert_HIghest.ipynb","provenance":[{"file_id":"1ftGKQ22ZBSIX_d6KEpUI7vRczYgtQPMF","timestamp":1620983839237},{"file_id":"https://github.com/prateekjoshi565/Fine-Tuning-BERT/blob/master/Fine_Tuning_BERT_for_Spam_Classification.ipynb","timestamp":1619947106006}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"OFOTiqrtNvyy"},"source":["# Install Transformers Library"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KYdY0n7CPkxa","executionInfo":{"status":"ok","timestamp":1626689398947,"user_tz":-330,"elapsed":442,"user":{"displayName":"swapnil kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9vEVcpw4Md19MxYrt28Nw5e4xMxyCx3xoMPqseg=s64","userId":"09398363863484464628"}},"outputId":"470e9c68-46a2-4e31-dbda-8d0ad6949ad1"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mon Jul 19 10:09:58 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   51C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7sYuExU3YiR4","executionInfo":{"status":"ok","timestamp":1626689389778,"user_tz":-330,"elapsed":19061,"user":{"displayName":"swapnil kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9vEVcpw4Md19MxYrt28Nw5e4xMxyCx3xoMPqseg=s64","userId":"09398363863484464628"}},"outputId":"9b4774fc-3b95-48c6-b80f-9d2dc401aa0e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1hkhc10wNrGt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626689396215,"user_tz":-330,"elapsed":6444,"user":{"displayName":"swapnil kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9vEVcpw4Md19MxYrt28Nw5e4xMxyCx3xoMPqseg=s64","userId":"09398363863484464628"}},"outputId":"6dd26b13-e11d-4ceb-b33d-c0288cc12249"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 9.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 49.5MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 35.2MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting huggingface-hub==0.0.12\n","  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.5.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4giRzM7NtHJ","executionInfo":{"status":"ok","timestamp":1626689415427,"user_tz":-330,"elapsed":4988,"user":{"displayName":"swapnil kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9vEVcpw4Md19MxYrt28Nw5e4xMxyCx3xoMPqseg=s64","userId":"09398363863484464628"}}},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast\n","\n","# specify GPU\n","device = torch.device(\"cuda\")"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kKd-Tj3hOMsZ"},"source":["# Load Dataset"]},{"cell_type":"code","metadata":{"id":"cwJrQFQgN_BE","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"error","timestamp":1626689415435,"user_tz":-330,"elapsed":15,"user":{"displayName":"swapnil kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9vEVcpw4Md19MxYrt28Nw5e4xMxyCx3xoMPqseg=s64","userId":"09398363863484464628"}},"outputId":"c9fb997a-293f-4b6f-ee15-6c77f66fcd93"},"source":["df = pd.read_json('/content/drive/MyDrive/sercasm/twitter/sarcasm_detection_shared_task_twitter_training.jsonl',lines=True)\n","df1 = pd.read_json('/content/drive/MyDrive/sercasm/twitter/sarcasm_detection_shared_task_twitter_testing.jsonl',lines=True)\n","\n","df['labels'] = df['label'].apply(lambda x: ['SARCASM', 'NOT_SARCASM'].index(x))\n","df1['labels'] = df1['label'].apply(lambda x: ['SARCASM', 'NOT_SARCASM'].index(x))\n","df1.tail()"],"execution_count":5,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-17eb895f0d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/sercasm/twitter/sarcasm_detection_shared_task_twitter_training.jsonl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/sercasm/twitter/sarcasm_detection_shared_task_twitter_testing.jsonl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'SARCASM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NOT_SARCASM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'SARCASM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NOT_SARCASM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows)\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    751\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1119\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m             )\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected object or value"]}]},{"cell_type":"code","metadata":{"id":"U7WBye79ZKoO"},"source":["df[\"tweets\"]=df['response']\n","df1[\"tweets\"]=df1['response']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fzPPOrVQWiW5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620983799629,"user_tz":420,"elapsed":1380,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"250d69ff-e09b-4702-de7d-94eb9b2f4e3d"},"source":["df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5000, 5)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"676DPU1BOPdp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620983801150,"user_tz":420,"elapsed":1582,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"fcd58b7b-ec59-4d9f-df91-5104d186e5df"},"source":["# check class distribution\n","df['labels'].value_counts(normalize = True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    0.5\n","0    0.5\n","Name: labels, dtype: float64"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"MKfWnApvOoE7"},"source":["# Split train dataset into train, validation and test sets"]},{"cell_type":"code","metadata":{"id":"mfhSPF5jOWb7"},"source":["\n","X_s = df['tweets'].values\n","y_s = df['labels'].values\n","\n","Xt_s = df1['tweets'].values\n","yt_s = df1['labels'].values\n","\n","train_text, temp_text, train_labels, temp_labels = X_s,Xt_s,y_s,yt_s\n","\n","# we will use temp_text and temp_labels to create validation and test set\n","val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n","                                                                random_state=2018, \n","                                                                test_size=0.5, \n","                                                                stratify=temp_labels)\n","val_text, test_text, val_labels, test_labels=temp_text, temp_text, temp_labels, temp_labels\n","\n","# X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.2, random_state=42)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1jEFb39cCjk","executionInfo":{"status":"ok","timestamp":1619980120545,"user_tz":420,"elapsed":7188,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"f307cc28-6d6f-4f48-df47-e978089fffa5"},"source":["# pip install -U sentence-transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: sentence-transformers in /usr/local/lib/python3.7/dist-packages (1.1.0)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n","Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n","Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.95)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n","Requirement already satisfied, skipping upgrade: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.5.1)\n","Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.45)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.10.1)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n","Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.2)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n","Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n7hsdLoCO7uB"},"source":["# Import BERT Model and BERT Tokenizer\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"S1kY3gZjO2RE"},"source":["# import BERT-base pretrained model\n","bert = AutoModel.from_pretrained('bert-base-uncased')\n","\n","# Load the BERT tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_zOKeOMeO-DT"},"source":["# sample data\n","text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n","# encode text\n","sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oAH73n39PHLw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619980123432,"user_tz":420,"elapsed":10061,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"29db573b-b435-4ad7-b5bc-f1173c03a77b"},"source":["# output\n","print(sent_id)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8wIYaWI_Prg8"},"source":["# Tokenization"]},{"cell_type":"code","metadata":{"id":"yKwbpeN_PMiu","colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"status":"ok","timestamp":1619980123432,"user_tz":420,"elapsed":10054,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"f48ad682-55a3-4245-c623-7557786a368c"},"source":["# get length of all the messages in the train set\n","seq_len = [len(i.split()) for i in train_text]\n","\n","pd.Series(seq_len).hist(bins = 30)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7faf34deb290>"]},"metadata":{"tags":[]},"execution_count":459},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"OXcswEIRPvGe"},"source":["max_seq_len = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tk5S7DWaP2t6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619980125017,"user_tz":420,"elapsed":11628,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"39505d62-f9e8-4a9f-b8ad-46d8bd284f81"},"source":["# tokenize and encode sequences in the training set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Wsm8bkRZQTw9"},"source":["# Convert Integer Sequences to Tensors"]},{"cell_type":"code","metadata":{"id":"QR-lXwmzQPd6"},"source":["# for train set\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","# for validation set\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","# for test set\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ov1cOBlcRLuk"},"source":["# Create DataLoaders"]},{"cell_type":"code","metadata":{"id":"qUy9JKFYQYLp"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","#define a batch size\n","batch_size = 32\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K2HZc5ZYRV28"},"source":["# Freeze BERT Parameters"]},{"cell_type":"code","metadata":{"id":"wHZ0MC00RQA_"},"source":["# freeze all the parameters\n","for param in bert.parameters():\n","    param.requires_grad = True\n","# print(bert)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s7ahGBUWRi3X"},"source":["# Define Model Architecture"]},{"cell_type":"code","metadata":{"id":"b3iEtGyYRd0A"},"source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, bert):\n","      \n","      super(BERT_Arch, self).__init__()\n","\n","      self.bert = bert \n","      \n","      # dropout layer\n","      self.dropout = nn.Dropout(0.1)\n","      \n","      # relu activation function\n","      self.relu =  nn.ReLU()\n","\n","      # dense layer 1\n","      self.fc1 = nn.Linear(768,512)\n","      \n","      # dense layer 2 (Output layer)\n","      self.fc2 = nn.Linear(512,2)\n","\n","      #softmax activation function\n","      self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","\n","      #pass the inputs to the model  \n","      _, cls_hs = self.bert(sent_id,mask, return_dict=False)\n","      \n","      x = self.fc1(cls_hs)\n","\n","      x = self.relu(x)\n","\n","      x = self.dropout(x)\n","\n","      # output layer\n","      x = self.fc2(x)\n","      \n","      # apply softmax activation\n","      x = self.softmax(x)\n","\n","      return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cBAJJVuJRliv"},"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(bert)\n","\n","# push the model to GPU\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"taXS0IilRn9J"},"source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = AdamW(model.parameters(), lr = 2e-5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j9CDpoMQR_rK"},"source":["# Find Class Weights"]},{"cell_type":"code","metadata":{"id":"izY5xH5eR7Ur","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619980125024,"user_tz":420,"elapsed":11604,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"e7f638e9-f2ea-44d3-e8a1-f3c34c494e4a"},"source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","#compute the class weights\n","class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n","\n","print(class_wts)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1. 1.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r1WvfY2vSGKi"},"source":["# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","cross_entropy  = nn.NLLLoss(weight=weights) \n","\n","# number of training epochs\n","epochs = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"My4CA0qaShLq"},"source":["# Fine-Tune BERT"]},{"cell_type":"code","metadata":{"id":"rskLk8R_SahS"},"source":["# function to train the model\n","def train():\n","  \n","  model.train()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save model predictions\n","  total_preds=[]\n","  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):\n","    \n","    # progress update after every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n"," \n","    sent_id, mask, labels = batch\n","\n","    # clear previously calculated gradients \n","    model.zero_grad()        \n","\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask)\n","\n","    # compute the loss between actual and predicted values\n","    loss = cross_entropy(preds, labels)\n","\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    # update parameters\n","    optimizer.step()\n","\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)\n","  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yGXovFDlSxB5"},"source":["# function for evaluating the model\n","def evaluate():\n","  \n","  print(\"\\nEvaluating...\")\n","  \n","  # deactivate dropout layers\n","  model.eval()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save the model predictions\n","  total_preds = []\n","\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):\n","    \n","    # Progress update every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      \n","      # Calculate elapsed time in minutes.\n","      # elapsed = format_time(time.time() - t0)\n","            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","\n","    sent_id, mask, labels = batch\n","\n","    # deactivate autograd\n","    with torch.no_grad():\n","      \n","      # model predictions\n","      preds = model(sent_id, mask)\n","\n","      # compute the validation loss between actual and predicted values\n","      loss = cross_entropy(preds,labels)\n","\n","      total_loss = total_loss + loss.item()\n","\n","      preds = preds.detach().cpu().numpy()\n","\n","      total_preds.append(preds)\n","\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9KZEgxRRTLXG"},"source":["# Start Model Training"]},{"cell_type":"code","metadata":{"id":"k1USGTntS3TS"},"source":["# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","#for each epoch\n","epochs=10\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss,_ = train()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'saved_weights.pt')\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    \n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_yrhUc9kTI5a"},"source":["# Load Saved Model"]},{"cell_type":"code","metadata":{"id":"OacxUyizS8d1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619980628368,"user_tz":420,"elapsed":1284,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"1494bb34-6152-4a7f-9a6a-523093c25026"},"source":["#load weights of best model\n","path = 'saved_weights.pt'\n","model.load_state_dict(torch.load(path))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":474}]},{"cell_type":"markdown","metadata":{"id":"x4SVftkkTZXA"},"source":["# Get Predictions for Test Data"]},{"cell_type":"code","metadata":{"id":"NZl0SZmFTRQA"},"source":["# get predictions for test data\n","with torch.no_grad():\n","  preds = model(test_seq.to(device), test_mask.to(device))\n","  preds = preds.detach().cpu().numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ms1ObHZxTYSI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619980634494,"user_tz":420,"elapsed":3929,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"491633bf-dd48-4aaf-c5cc-644648bcb46c"},"source":["# model's performance\n","preds = np.argmax(preds, axis = 1)\n","print(classification_report(test_y, preds))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.70      0.81      0.75       900\n","           1       0.78      0.66      0.71       900\n","\n","    accuracy                           0.73      1800\n","   macro avg       0.74      0.73      0.73      1800\n","weighted avg       0.74      0.73      0.73      1800\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YqzLS7rHTp4T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619980634495,"user_tz":420,"elapsed":2547,"user":{"displayName":"ABHISHEK RANJAN","photoUrl":"","userId":"15498253178039914064"}},"outputId":"0517b409-2a7a-45c1-f048-524e6887d53f"},"source":["# confusion matrix\n","# pd.crosstab(test_y, preds)\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","print(accuracy_score(test_y, preds))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.7338888888888889\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jpX1uTwjUPY6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BY2P7H1W2Wo4"},"source":[""],"execution_count":null,"outputs":[]}]}